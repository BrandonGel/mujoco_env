{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ec62aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:08<00:17,  8.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.9511812329292297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:16<00:08,  8.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: 0.774529218673706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:24<00:00,  8.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, loss: 0.7073671817779541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_dataset():\n",
    "    return datasets.FashionMNIST(\n",
    "        root=\"/tmp/data\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=ToTensor(),\n",
    "    )\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        inputs = self.flatten(inputs)\n",
    "        logits = self.linear_relu_stack(inputs)\n",
    "        return logits\n",
    "\n",
    "def train_func():\n",
    "    num_epochs = 3\n",
    "    batch_size = 64\n",
    "\n",
    "    dataset = get_dataset()\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "    model = NeuralNetwork()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        for inputs, labels in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(inputs)\n",
    "            loss = criterion(pred, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"epoch: {epoch}, loss: {loss.item()}\")\n",
    "\n",
    "train_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2839598",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 01:25:57,031\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-06-08 01:25:57 (running for 00:00:00.11)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/12 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-08_01-17-28_597852_193779/artifacts/2025-06-08_01-25-57/TorchTrainer_2025-06-08_01-25-57/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-08 01:26:02 (running for 00:00:05.16)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/12 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-08_01-17-28_597852_193779/artifacts/2025-06-08_01-25-57/TorchTrainer_2025-06-08_01-25-57/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-08 01:26:07 (running for 00:00:10.21)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/12 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-08_01-17-28_597852_193779/artifacts/2025-06-08_01-25-57/TorchTrainer_2025-06-08_01-25-57/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-08 01:26:12 (running for 00:00:15.24)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/12 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-08_01-17-28_597852_193779/artifacts/2025-06-08_01-25-57/TorchTrainer_2025-06-08_01-25-57/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-08 01:26:17 (running for 00:00:20.30)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/12 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-08_01-17-28_597852_193779/artifacts/2025-06-08_01-25-57/TorchTrainer_2025-06-08_01-25-57/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-08 01:26:22 (running for 00:00:25.35)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/12 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-08_01-17-28_597852_193779/artifacts/2025-06-08_01-25-57/TorchTrainer_2025-06-08_01-25-57/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-08 01:26:27 (running for 00:00:30.40)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/12 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-08_01-17-28_597852_193779/artifacts/2025-06-08_01-25-57/TorchTrainer_2025-06-08_01-25-57/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-08 01:26:32 (running for 00:00:35.45)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/12 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-08_01-17-28_597852_193779/artifacts/2025-06-08_01-25-57/TorchTrainer_2025-06-08_01-25-57/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-08 01:26:37 (running for 00:00:40.51)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/12 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-08_01-17-28_597852_193779/artifacts/2025-06-08_01-25-57/TorchTrainer_2025-06-08_01-25-57/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-08 01:26:42 (running for 00:00:45.56)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/12 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-08_01-17-28_597852_193779/artifacts/2025-06-08_01-25-57/TorchTrainer_2025-06-08_01-25-57/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-08 01:26:47 (running for 00:00:50.61)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/12 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-08_01-17-28_597852_193779/artifacts/2025-06-08_01-25-57/TorchTrainer_2025-06-08_01-25-57/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-08 01:26:52 (running for 00:00:55.66)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/12 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-08_01-17-28_597852_193779/artifacts/2025-06-08_01-25-57/TorchTrainer_2025-06-08_01-25-57/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 01:26:57,345\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. Training has not started in the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 1.0 CPUs and 4.0 GPUs, but the cluster only has 12.0 CPUs and 1.0 GPUs available. Stop the training and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-06-08 01:26:57 (running for 00:01:00.72)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/12 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-08_01-17-28_597852_193779/artifacts/2025-06-08_01-25-57/TorchTrainer_2025-06-08_01-25-57/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-08 01:27:02 (running for 00:01:05.76)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/12 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-08_01-17-28_597852_193779/artifacts/2025-06-08_01-25-57/TorchTrainer_2025-06-08_01-25-57/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-08 01:27:07 (running for 00:01:10.81)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/12 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-08_01-17-28_597852_193779/artifacts/2025-06-08_01-25-57/TorchTrainer_2025-06-08_01-25-57/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-08 01:27:12 (running for 00:01:15.86)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/12 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-08_01-17-28_597852_193779/artifacts/2025-06-08_01-25-57/TorchTrainer_2025-06-08_01-25-57/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-08 01:27:17 (running for 00:01:20.91)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/12 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-08_01-17-28_597852_193779/artifacts/2025-06-08_01-25-57/TorchTrainer_2025-06-08_01-25-57/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-08 01:27:22 (running for 00:01:25.96)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/12 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-08_01-17-28_597852_193779/artifacts/2025-06-08_01-25-57/TorchTrainer_2025-06-08_01-25-57/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-08 01:27:28 (running for 00:01:31.01)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/12 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-08_01-17-28_597852_193779/artifacts/2025-06-08_01-25-57/TorchTrainer_2025-06-08_01-25-57/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-08 01:27:33 (running for 00:01:36.06)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/12 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-08_01-17-28_597852_193779/artifacts/2025-06-08_01-25-57/TorchTrainer_2025-06-08_01-25-57/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-08 01:27:38 (running for 00:01:41.11)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/12 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-08_01-17-28_597852_193779/artifacts/2025-06-08_01-25-57/TorchTrainer_2025-06-08_01-25-57/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-08 01:27:43 (running for 00:01:46.15)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/12 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-08_01-17-28_597852_193779/artifacts/2025-06-08_01-25-57/TorchTrainer_2025-06-08_01-25-57/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-08 01:27:48 (running for 00:01:51.20)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/12 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-08_01-17-28_597852_193779/artifacts/2025-06-08_01-25-57/TorchTrainer_2025-06-08_01-25-57/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-08 01:27:53 (running for 00:01:56.23)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/12 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-08_01-17-28_597852_193779/artifacts/2025-06-08_01-25-57/TorchTrainer_2025-06-08_01-25-57/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 01:27:57,409\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. Training has not started in the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 1.0 CPUs and 4.0 GPUs, but the cluster only has 12.0 CPUs and 1.0 GPUs available. Stop the training and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-06-08 01:27:58 (running for 00:02:01.29)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/12 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-08_01-17-28_597852_193779/artifacts/2025-06-08_01-25-57/TorchTrainer_2025-06-08_01-25-57/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-08 01:28:03 (running for 00:02:06.33)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/12 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-08_01-17-28_597852_193779/artifacts/2025-06-08_01-25-57/TorchTrainer_2025-06-08_01-25-57/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-08 01:28:08 (running for 00:02:11.37)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/12 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-08_01-17-28_597852_193779/artifacts/2025-06-08_01-25-57/TorchTrainer_2025-06-08_01-25-57/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-08 01:28:13 (running for 00:02:16.40)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/12 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-08_01-17-28_597852_193779/artifacts/2025-06-08_01-25-57/TorchTrainer_2025-06-08_01-25-57/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-08 01:28:18 (running for 00:02:21.45)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/12 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-08_01-17-28_597852_193779/artifacts/2025-06-08_01-25-57/TorchTrainer_2025-06-08_01-25-57/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-08 01:28:23 (running for 00:02:26.49)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/12 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-08_01-17-28_597852_193779/artifacts/2025-06-08_01-25-57/TorchTrainer_2025-06-08_01-25-57/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-08 01:28:28 (running for 00:02:31.54)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/12 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-08_01-17-28_597852_193779/artifacts/2025-06-08_01-25-57/TorchTrainer_2025-06-08_01-25-57/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 01:28:31,298\tWARNING tune.py:219 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2025-06-08 01:28:31,301\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/brandon-ho/ray_results/TorchTrainer_2025-06-08_01-25-57' in 0.0025s.\n",
      "2025-06-08 01:28:31,304\tINFO tune.py:1041 -- Total run time: 154.27 seconds (154.26 seconds for the tuning loop).\n",
      "2025-06-08 01:28:31,305\tWARNING tune.py:1051 -- Training has been interrupted, but the most recent state was saved.\n",
      "Resume training with: <FrameworkTrainer>.restore(path=\"/home/brandon-ho/ray_results/TorchTrainer_2025-06-08_01-25-57\", ...)\n",
      "2025-06-08 01:28:31,307\tWARNING experiment_analysis.py:180 -- Failed to fetch metrics for 1 trial(s):\n",
      "- TorchTrainer_0e280_00000: FileNotFoundError('Could not fetch metrics for TorchTrainer_0e280_00000: both result.json and progress.csv were not found at /home/brandon-ho/ray_results/TorchTrainer_2025-06-08_01-25-57/TorchTrainer_0e280_00000_0_2025-06-08_01-25-57')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-06-08 01:28:31 (running for 00:02:34.26)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/12 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-08_01-17-28_597852_193779/artifacts/2025-06-08_01-25-57/TorchTrainer_2025-06-08_01-25-57/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import ray.train.torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_func_distributed():\n",
    "    num_epochs = 3\n",
    "    batch_size = 64\n",
    "\n",
    "    dataset = get_dataset()\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    dataloader = ray.train.torch.prepare_data_loader(dataloader)\n",
    "\n",
    "    model = NeuralNetwork()\n",
    "    model = ray.train.torch.prepare_model(model)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        if ray.train.get_context().get_world_size() > 1:\n",
    "            dataloader.sampler.set_epoch(epoch)\n",
    "\n",
    "        for inputs, labels in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(inputs)\n",
    "            loss = criterion(pred, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"epoch: {epoch}, loss: {loss.item()}\")\n",
    "from ray.train.torch import TorchTrainer\n",
    "from ray.train import ScalingConfig\n",
    "\n",
    "# For GPU Training, set `use_gpu` to True.\n",
    "use_gpu = True\n",
    "\n",
    "trainer = TorchTrainer(\n",
    "    train_func_distributed,\n",
    "    scaling_config=ScalingConfig(num_workers=4, use_gpu=use_gpu)\n",
    ")\n",
    "\n",
    "results = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e53373e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2025-06-08 01:29:12</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:01.45        </td></tr>\n",
       "<tr><td>Memory:      </td><td>10.2/31.2 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 1.0/12 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">    a</th><th style=\"text-align: right;\">  b</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  score</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>objective_81db8_00000</td><td>TERMINATED</td><td>192.168.0.18:198861</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">  2</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.00025177 </td><td style=\"text-align: right;\"> 2     </td></tr>\n",
       "<tr><td>objective_81db8_00001</td><td>TERMINATED</td><td>192.168.0.18:198862</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">  1</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.000261307</td><td style=\"text-align: right;\"> 1.0001</td></tr>\n",
       "<tr><td>objective_81db8_00002</td><td>TERMINATED</td><td>192.168.0.18:198864</td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">  1</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.000218391</td><td style=\"text-align: right;\"> 1.01  </td></tr>\n",
       "<tr><td>objective_81db8_00003</td><td>TERMINATED</td><td>192.168.0.18:198863</td><td style=\"text-align: right;\">1    </td><td style=\"text-align: right;\">  2</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.000219345</td><td style=\"text-align: right;\"> 3     </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 01:29:12,604\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/brandon-ho/ray_results/objective_2025-06-08_01-29-11' in 0.0045s.\n",
      "2025-06-08 01:29:12,607\tINFO tune.py:1041 -- Total run time: 1.46 seconds (1.45 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1.0, 'b': 2}\n"
     ]
    }
   ],
   "source": [
    "from ray import tune\n",
    "\n",
    "\n",
    "def objective(config):  # ①\n",
    "    score = config[\"a\"] ** 2 + config[\"b\"]\n",
    "    return {\"score\": score}\n",
    "\n",
    "\n",
    "search_space = {  # ②\n",
    "    \"a\": tune.grid_search([0.001, 0.01, 0.1, 1.0]),\n",
    "    \"b\": tune.choice([1, 2, 3]),\n",
    "}\n",
    "\n",
    "tuner = tune.Tuner(objective, param_space=search_space)  # ③\n",
    "\n",
    "results = tuner.fit()\n",
    "print(results.get_best_result(metric=\"score\", mode=\"max\").config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ef38a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brandon-ho/miniconda3/envs/mujoco_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-06-08 01:32:10,758\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2025-06-08 01:32:11,202\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2025-06-08 01:32:11,850\tWARNING algorithm_config.py:4968 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n",
      "2025-06-08 01:32:11,851\tWARNING algorithm_config.py:4997 -- You configured a custom `model` config (probably through calling config.training(model=..), whereas your config uses the new API stack! In order to switch off the new API stack, set in your config: `config.api_stack(enable_rl_module_and_learner=False, enable_env_runner_and_connector_v2=False)`. If you DO want to use the new API stack, configure your model, instead, through: `config.rl_module(model_config={..})`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up the PPO configuration...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brandon-ho/miniconda3/envs/mujoco_env/lib/python3.11/site-packages/ray/rllib/algorithms/algorithm.py:521: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/home/brandon-ho/miniconda3/envs/mujoco_env/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/brandon-ho/miniconda3/envs/mujoco_env/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/brandon-ho/miniconda3/envs/mujoco_env/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "2025-06-08 01:32:12,773\tINFO worker.py:1888 -- Started a local Ray instance.\n",
      "\u001b[36m(SingleAgentEnvRunner pid=199863)\u001b[0m 2025-06-08 01:32:16,639\tWARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!\n",
      "2025-06-08 01:32:16,886\tWARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!\n",
      "2025-06-08 01:32:16,919\tWARNING algorithm_config.py:4997 -- You configured a custom `model` config (probably through calling config.training(model=..), whereas your config uses the new API stack! In order to switch off the new API stack, set in your config: `config.api_stack(enable_rl_module_and_learner=False, enable_env_runner_and_connector_v2=False)`. If you DO want to use the new API stack, configure your model, instead, through: `config.rl_module(model_config={..})`.\n",
      "2025-06-08 01:32:17,990\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training loop...\n",
      "Iteration 1\n",
      "  Training metrics: {'env_to_module_connector': {'timers': {'connectors': {'add_observations_from_episodes_to_batch': np.float64(9.987235734148889e-06), 'numpy_to_tensor': np.float64(4.2680838781411974e-05), 'add_time_dim_to_batch_and_zero_pad': np.float64(9.446649436100315e-06), 'add_states_from_episodes_to_batch': np.float64(5.240405638219443e-06), 'batch_individual_items': np.float64(2.345708717526926e-05)}}, 'connector_pipeline_timer': np.float64(0.00014628796608229556)}, 'num_env_steps_sampled': 4000, 'module_to_env_connector': {'timers': {'connectors': {'un_batch_to_individual_items': np.float64(2.0546734033118183e-05), 'tensor_to_numpy': np.float64(6.456608921658124e-05), 'normalize_and_clip_actions': np.float64(3.4387110817761923e-05), 'get_actions': np.float64(0.0002275230064821435), 'listify_data_for_vector_env': np.float64(4.075788345284659e-05), 'remove_single_ts_time_rank_from_batch': np.float64(2.3294462288748326e-06)}}, 'connector_pipeline_timer': np.float64(0.00046997925121988054)}, 'num_env_steps_sampled_lifetime': 4000, 'sample': np.float64(1.229644648003159), 'env_step_timer': np.float64(4.405839576049295e-05), 'weights_seq_no': 0.0, 'env_to_module_sum_episodes_length_out': np.float64(1234.3334832671244), 'env_reset_timer': np.float64(0.00016510633092063168), 'rlmodule_inference_timer': np.float64(0.00015155735537089642), 'num_agent_steps_sampled_lifetime': {'default_agent': 4000}, 'num_episodes': 0, 'num_agent_steps_sampled': {'default_agent': 4000}, 'num_module_steps_sampled_lifetime': {'default_policy': 4000}, 'num_module_steps_sampled': {'default_policy': 4000}, 'num_episodes_lifetime': 0, 'env_to_module_sum_episodes_length_in': np.float64(1234.3334832671244), 'num_env_steps_sampled_lifetime_throughput': nan}\n",
      "Iteration 2\n",
      "  Training metrics: {'env_to_module_connector': {'timers': {'connectors': {'add_observations_from_episodes_to_batch': np.float64(9.948303234563863e-06), 'numpy_to_tensor': np.float64(4.250835810851418e-05), 'add_time_dim_to_batch_and_zero_pad': np.float64(9.406228652233137e-06), 'add_states_from_episodes_to_batch': np.float64(5.217622729200317e-06), 'batch_individual_items': np.float64(2.336050373601151e-05)}}, 'connector_pipeline_timer': np.float64(0.00014570778859061815)}, 'num_env_steps_sampled': 4000, 'module_to_env_connector': {'timers': {'connectors': {'un_batch_to_individual_items': np.float64(2.0456382609791077e-05), 'tensor_to_numpy': np.float64(6.430510880015109e-05), 'normalize_and_clip_actions': np.float64(3.4258348364631646e-05), 'get_actions': np.float64(0.00022655540349775813), 'listify_data_for_vector_env': np.float64(4.061608874455588e-05), 'remove_single_ts_time_rank_from_batch': np.float64(2.318669619813039e-06)}}, 'connector_pipeline_timer': np.float64(0.0004680554388342123)}, 'num_env_steps_sampled_lifetime': 8000, 'sample': np.float64(1.2296090251168967), 'env_step_timer': np.float64(4.388229800197661e-05), 'weights_seq_no': 1.0, 'env_to_module_sum_episodes_length_out': np.float64(1220.843370477072), 'env_reset_timer': np.float64(0.00016510633092063168), 'rlmodule_inference_timer': np.float64(0.00015091852445351086), 'num_agent_steps_sampled_lifetime': {'default_agent': 8000}, 'num_episodes': 6, 'num_agent_steps_sampled': {'default_agent': 4000}, 'num_module_steps_sampled_lifetime': {'default_policy': 8000}, 'num_module_steps_sampled': {'default_policy': 4000}, 'num_episodes_lifetime': 6, 'env_to_module_sum_episodes_length_in': np.float64(1220.843370477072), 'module_episode_returns_mean': {'default_policy': -66.23333333333234}, 'time_between_sampling': np.float64(5.698214523659165), 'episode_duration_sec_mean': 0.5966759198393751, 'episode_return_max': -11.399999999999972, 'episode_return_mean': -66.23333333333234, 'agent_episode_returns_mean': {'default_agent': -66.23333333333234}, 'episode_return_min': -156.59999999999678, 'episode_len_min': 125, 'episode_len_mean': 673.3333333333334, 'episode_len_max': 1577, 'num_env_steps_sampled_lifetime_throughput': 550.9523855635308}\n",
      "Iteration 3\n",
      "  Training metrics: {'env_to_module_connector': {'timers': {'connectors': {'add_observations_from_episodes_to_batch': np.float64(9.96597141212824e-06), 'numpy_to_tensor': np.float64(4.2635604467872804e-05), 'add_time_dim_to_batch_and_zero_pad': np.float64(9.434457198682357e-06), 'add_states_from_episodes_to_batch': np.float64(5.231462719577685e-06), 'batch_individual_items': np.float64(2.3398625355749696e-05)}}, 'connector_pipeline_timer': np.float64(0.0001460410409233845)}, 'num_env_steps_sampled': 4000, 'module_to_env_connector': {'timers': {'connectors': {'un_batch_to_individual_items': np.float64(2.0483529738079947e-05), 'tensor_to_numpy': np.float64(6.444389410699353e-05), 'normalize_and_clip_actions': np.float64(3.434307800928863e-05), 'get_actions': np.float64(0.00022707123637677974), 'listify_data_for_vector_env': np.float64(4.0697091194108675e-05), 'remove_single_ts_time_rank_from_batch': np.float64(2.3215526690473738e-06)}}, 'connector_pipeline_timer': np.float64(0.0004690390520843112)}, 'num_env_steps_sampled_lifetime': 12000, 'sample': np.float64(1.2296090754229758), 'env_step_timer': np.float64(4.399935891730605e-05), 'weights_seq_no': 2.0, 'env_to_module_sum_episodes_length_out': np.float64(1186.0191812545731), 'env_reset_timer': np.float64(0.00016510633092063168), 'rlmodule_inference_timer': np.float64(0.0001513256275872762), 'num_agent_steps_sampled_lifetime': {'default_agent': 12000}, 'num_episodes': 39, 'num_agent_steps_sampled': {'default_agent': 4000}, 'num_module_steps_sampled_lifetime': {'default_policy': 12000}, 'num_module_steps_sampled': {'default_policy': 4000}, 'num_episodes_lifetime': 45, 'env_to_module_sum_episodes_length_in': np.float64(1186.0191812545731), 'module_episode_returns_mean': {'default_policy': -11.784313725490135}, 'time_between_sampling': np.float64(5.698350361200884), 'episode_duration_sec_mean': 0.12309560632217886, 'episode_return_max': -1.9000000000000012, 'episode_return_mean': -11.784313725490135, 'agent_episode_returns_mean': {'default_agent': -11.784313725490135}, 'episode_return_min': -269.09999999999343, 'episode_len_min': 30, 'episode_len_mean': 128.84313725490193, 'episode_len_max': 2702, 'num_env_steps_sampled_lifetime_throughput': 558.9204761989141}\n",
      "Iteration 4\n",
      "  Training metrics: {'env_to_module_connector': {'timers': {'connectors': {'add_observations_from_episodes_to_batch': np.float64(9.953240666836108e-06), 'numpy_to_tensor': np.float64(4.260052715554363e-05), 'add_time_dim_to_batch_and_zero_pad': np.float64(9.418249822067025e-06), 'add_states_from_episodes_to_batch': np.float64(5.227084307726878e-06), 'batch_individual_items': np.float64(2.3374440744483285e-05)}}, 'connector_pipeline_timer': np.float64(0.00014590241675933697)}, 'num_env_steps_sampled': 4000, 'module_to_env_connector': {'timers': {'connectors': {'un_batch_to_individual_items': np.float64(2.0462880020041198e-05), 'tensor_to_numpy': np.float64(6.440489061257588e-05), 'normalize_and_clip_actions': np.float64(3.4318224443727925e-05), 'get_actions': np.float64(0.00022675090784323793), 'listify_data_for_vector_env': np.float64(4.06931108733563e-05), 'remove_single_ts_time_rank_from_batch': np.float64(2.318645462397943e-06)}}, 'connector_pipeline_timer': np.float64(0.00046859128999961246)}, 'num_env_steps_sampled_lifetime': 16000, 'sample': np.float64(1.2296119115051), 'env_step_timer': np.float64(4.396814011217291e-05), 'weights_seq_no': 3.0, 'env_to_module_sum_episodes_length_out': np.float64(1151.5337019619687), 'env_reset_timer': np.float64(0.00016510633092063168), 'rlmodule_inference_timer': np.float64(0.0001511425291889947), 'num_agent_steps_sampled_lifetime': {'default_agent': 16000}, 'num_episodes': 92, 'num_agent_steps_sampled': {'default_agent': 4000}, 'num_module_steps_sampled_lifetime': {'default_policy': 16000}, 'num_module_steps_sampled': {'default_policy': 4000}, 'num_episodes_lifetime': 137, 'env_to_module_sum_episodes_length_in': np.float64(1151.5337019619687), 'module_episode_returns_mean': {'default_policy': -3.6470588235294095}, 'time_between_sampling': np.float64(5.6985132083003185), 'episode_duration_sec_mean': 0.04172832826574735, 'episode_return_max': -1.5000000000000009, 'episode_return_mean': -3.6470588235294095, 'agent_episode_returns_mean': {'default_agent': -3.6470588235294095}, 'episode_return_min': -8.699999999999982, 'episode_len_min': 26, 'episode_len_mean': 47.470588235294116, 'episode_len_max': 98, 'num_env_steps_sampled_lifetime_throughput': 549.1883144445117}\n",
      "Iteration 5\n",
      "  Training metrics: {'env_to_module_connector': {'timers': {'connectors': {'add_observations_from_episodes_to_batch': np.float64(9.933005731829495e-06), 'numpy_to_tensor': np.float64(4.252104025312722e-05), 'add_time_dim_to_batch_and_zero_pad': np.float64(9.3988767557223e-06), 'add_states_from_episodes_to_batch': np.float64(5.2150950165047494e-06), 'batch_individual_items': np.float64(2.3323498222147122e-05)}}, 'connector_pipeline_timer': np.float64(0.00014558999419597317)}, 'num_env_steps_sampled': 4000, 'module_to_env_connector': {'timers': {'connectors': {'un_batch_to_individual_items': np.float64(2.041517612423608e-05), 'tensor_to_numpy': np.float64(6.425264761332274e-05), 'normalize_and_clip_actions': np.float64(3.426341876439281e-05), 'get_actions': np.float64(0.00022627588173794084), 'listify_data_for_vector_env': np.float64(4.0613254599506786e-05), 'remove_single_ts_time_rank_from_batch': np.float64(2.3147341207165816e-06)}}, 'connector_pipeline_timer': np.float64(0.0004676132821881878)}, 'num_env_steps_sampled_lifetime': 20000, 'sample': np.float64(1.229623523271778), 'env_step_timer': np.float64(4.388400696797167e-05), 'weights_seq_no': 4.0, 'env_to_module_sum_episodes_length_out': np.float64(1117.7774011204297), 'env_reset_timer': np.float64(0.00016510633092063168), 'rlmodule_inference_timer': np.float64(0.00015087131447463274), 'num_agent_steps_sampled_lifetime': {'default_agent': 20000}, 'num_episodes': 130, 'num_agent_steps_sampled': {'default_agent': 4000}, 'num_module_steps_sampled_lifetime': {'default_policy': 20000}, 'num_module_steps_sampled': {'default_policy': 4000}, 'num_episodes_lifetime': 267, 'env_to_module_sum_episodes_length_in': np.float64(1117.7774011204297), 'module_episode_returns_mean': {'default_policy': -1.894117647058825}, 'time_between_sampling': np.float64(5.698771746132283), 'episode_duration_sec_mean': 0.02681082293965315, 'episode_return_max': -0.9000000000000006, 'episode_return_mean': -1.894117647058825, 'agent_episode_returns_mean': {'default_agent': -1.894117647058825}, 'episode_return_min': -3.3000000000000007, 'episode_len_min': 20, 'episode_len_mean': 29.941176470588236, 'episode_len_max': 44, 'num_env_steps_sampled_lifetime_throughput': 547.578669220629}\n",
      "\n",
      "Saved model checkpoint to: TrainingResult(checkpoint=Checkpoint(filesystem=local, path=/tmp/tmpy4lh9zoz), metrics={'timers': {'training_iteration': 6.921916598972599, 'restore_env_runners': 1.6944204380965676e-05, 'training_step': 6.921692192582195, 'env_runner_sampling_timer': 1.2591469736924918, 'learner_update_timer': 5.660280960796516, 'synch_weights': 0.0019552469912371474, 'synch_env_connectors': 0.0023477508448688606}, 'env_runners': {'env_to_module_connector': {'timers': {'connectors': {'add_observations_from_episodes_to_batch': np.float64(9.933005731829495e-06), 'numpy_to_tensor': np.float64(4.252104025312722e-05), 'add_time_dim_to_batch_and_zero_pad': np.float64(9.3988767557223e-06), 'add_states_from_episodes_to_batch': np.float64(5.2150950165047494e-06), 'batch_individual_items': np.float64(2.3323498222147122e-05)}}, 'connector_pipeline_timer': np.float64(0.00014558999419597317)}, 'num_env_steps_sampled': 4000, 'module_to_env_connector': {'timers': {'connectors': {'un_batch_to_individual_items': np.float64(2.041517612423608e-05), 'tensor_to_numpy': np.float64(6.425264761332274e-05), 'normalize_and_clip_actions': np.float64(3.426341876439281e-05), 'get_actions': np.float64(0.00022627588173794084), 'listify_data_for_vector_env': np.float64(4.0613254599506786e-05), 'remove_single_ts_time_rank_from_batch': np.float64(2.3147341207165816e-06)}}, 'connector_pipeline_timer': np.float64(0.0004676132821881878)}, 'num_env_steps_sampled_lifetime': 20000, 'sample': np.float64(1.229623523271778), 'env_step_timer': np.float64(4.388400696797167e-05), 'weights_seq_no': 4.0, 'env_to_module_sum_episodes_length_out': np.float64(1117.7774011204297), 'env_reset_timer': np.float64(0.00016510633092063168), 'rlmodule_inference_timer': np.float64(0.00015087131447463274), 'num_agent_steps_sampled_lifetime': {'default_agent': 20000}, 'num_episodes': 130, 'num_agent_steps_sampled': {'default_agent': 4000}, 'num_module_steps_sampled_lifetime': {'default_policy': 20000}, 'num_module_steps_sampled': {'default_policy': 4000}, 'num_episodes_lifetime': 267, 'env_to_module_sum_episodes_length_in': np.float64(1117.7774011204297), 'module_episode_returns_mean': {'default_policy': -1.894117647058825}, 'time_between_sampling': np.float64(5.698771746132283), 'episode_duration_sec_mean': 0.02681082293965315, 'episode_return_max': -0.9000000000000006, 'episode_return_mean': -1.894117647058825, 'agent_episode_returns_mean': {'default_agent': -1.894117647058825}, 'episode_return_min': -3.3000000000000007, 'episode_len_min': 20, 'episode_len_mean': 29.941176470588236, 'episode_len_max': 44, 'num_env_steps_sampled_lifetime_throughput': 547.578669220629}, 'learners': {'__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_one_ts_to_episodes_and_truncate': 0.0028199214844511844, 'batch_individual_items': 0.05103771170384309, 'general_advantage_estimation': 0.03632630795539967, 'add_observations_from_episodes_to_batch': 6.177343400300432e-05, 'numpy_to_tensor': 0.00021324824265851674, 'add_columns_from_episodes_to_train_batch': 0.05816072957563349, 'add_time_dim_to_batch_and_zero_pad': 3.3472375488589644e-05, 'add_states_from_episodes_to_batch': 1.2348121687848316e-05}}, 'connector_pipeline_timer': 0.14900734038845148}, 'num_env_steps_trained_lifetime': 19295170, 'num_module_steps_trained_lifetime': 608768, 'num_trainable_parameters': 133379.0, 'learner_connector_sum_episodes_length_out': 4003.0450118876, 'num_env_steps_trained': 4004877, 'num_module_steps_trained': 124032, 'learner_connector_sum_episodes_length_in': 4000.0, 'num_non_trainable_parameters': 0.0, 'num_env_steps_trained_lifetime_throughput': 0.0}, 'default_policy': {'default_optimizer_learning_rate': 5e-05, 'module_train_batch_size_mean': 128.0, 'policy_loss': np.float32(-0.280644), 'total_loss': np.float32(-0.15345696), 'weights_seq_no': 5.0, 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'gradients_default_optimizer_global_norm': np.float32(0.85237956), 'curr_kl_coeff': 0.3375000059604645, 'num_module_steps_trained_lifetime': 608768, 'num_trainable_parameters': 133379.0, 'vf_loss': np.float32(0.12122305), 'mean_kl_loss': np.float32(0.026506545), 'entropy': np.float32(0.3430178), 'num_module_steps_trained': 124032, 'vf_loss_unclipped': np.float32(0.12122305), 'curr_entropy_coeff': 0.0, 'vf_explained_var': np.float32(0.8009279)}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 20000, 'fault_tolerance': {'num_healthy_workers': 3, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 547.578669220629, 'done': False, 'training_iteration': 5, 'trial_id': 'default', 'date': '2025-06-08_01-32-53', 'timestamp': 1749360773, 'time_this_iter_s': 7.2944560050964355, 'time_total_s': 35.869109869003296, 'pid': 199634, 'hostname': 'brandon-ho-OMEN-by-HP-Laptop-15-dc0xxx', 'node_ip': '192.168.0.18', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': <class '__main__.SimpleCorridor'>, 'env_config': {'corridor_length': 20}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 3, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x730510b16840>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 35.869109869003296, 'iterations_since_restore': 5, 'perf': {'cpu_util_percent': np.float64(49.91818181818183), 'ram_util_percent': np.float64(34.13636363636365)}})\n",
      "\n",
      "Running inference with the trained policy...\n",
      "\n",
      "Agent trajectory:\n",
      "  Step 0: Position 0.0, Action: RIGHT\n",
      "  Step 1: Position 1.0, Action: RIGHT\n",
      "  Step 2: Position 2.0, Action: RIGHT\n",
      "  Step 3: Position 3.0, Action: RIGHT\n",
      "  Step 4: Position 4.0, Action: RIGHT\n",
      "  Step 5: Position 5.0, Action: RIGHT\n",
      "  Step 6: Position 6.0, Action: RIGHT\n",
      "  Step 7: Position 7.0, Action: RIGHT\n",
      "  Step 8: Position 8.0, Action: RIGHT\n",
      "  Step 9: Position 9.0, Action: RIGHT\n",
      "\n",
      "Episode complete:\n",
      "  Steps taken: 10\n",
      "  Total reward: 0.10\n",
      "  Final position: 10.0\n",
      "  Success! The agent has learned the optimal policy (always move right).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(SingleAgentEnvRunner pid=199869)\u001b[0m 2025-06-08 01:38:52,768\tWARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!\n",
      "\u001b[33m(raylet)\u001b[0m [2025-06-08 01:55:02,987 E 199795 199820] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-08_01-32-11_890739_199634 is over 95% full, available space: 4.77544 GB; capacity: 95.5616 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-06-08 01:55:12,998 E 199795 199820] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-08_01-32-11_890739_199634 is over 95% full, available space: 4.41908 GB; capacity: 95.5616 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-06-08 01:55:23,009 E 199795 199820] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-08_01-32-11_890739_199634 is over 95% full, available space: 4.08345 GB; capacity: 95.5616 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-06-08 01:55:33,019 E 199795 199820] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-08_01-32-11_890739_199634 is over 95% full, available space: 3.68655 GB; capacity: 95.5616 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-06-08 01:55:43,030 E 199795 199820] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-08_01-32-11_890739_199634 is over 95% full, available space: 3.33032 GB; capacity: 95.5616 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-06-08 01:55:53,036 E 199795 199820] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-08_01-32-11_890739_199634 is over 95% full, available space: 3.29406 GB; capacity: 95.5616 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-06-08 01:56:03,042 E 199795 199820] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-08_01-32-11_890739_199634 is over 95% full, available space: 2.37098 GB; capacity: 95.5616 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-06-08 01:56:13,049 E 199795 199820] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-08_01-32-11_890739_199634 is over 95% full, available space: 1.16693 GB; capacity: 95.5616 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-06-08 01:56:23,055 E 199795 199820] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-08_01-32-11_890739_199634 is over 95% full, available space: 0.1408 GB; capacity: 95.5616 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-06-08 01:56:33,066 E 199795 199820] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-08_01-32-11_890739_199634 is over 95% full, available space: 3.0028 GB; capacity: 95.5616 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-06-08 01:56:43,077 E 199795 199820] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-08_01-32-11_890739_199634 is over 95% full, available space: 3.00138 GB; capacity: 95.5616 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-06-08 01:56:53,089 E 199795 199820] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-08_01-32-11_890739_199634 is over 95% full, available space: 3.00109 GB; capacity: 95.5616 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-06-08 01:57:03,104 E 199795 199820] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-08_01-32-11_890739_199634 is over 95% full, available space: 3.00087 GB; capacity: 95.5616 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-06-08 01:57:13,115 E 199795 199820] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-08_01-32-11_890739_199634 is over 95% full, available space: 1.45145 GB; capacity: 95.5616 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-06-08 01:57:23,121 E 199795 199820] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-08_01-32-11_890739_199634 is over 95% full, available space: 1.03524 GB; capacity: 95.5616 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-06-08 01:57:33,125 E 199795 199820] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-08_01-32-11_890739_199634 is over 95% full, available space: 0.023674 GB; capacity: 95.5616 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-06-08 01:57:43,137 E 199795 199820] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-08_01-32-11_890739_199634 is over 95% full, available space: 1.54894 GB; capacity: 95.5616 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-06-08 01:57:53,149 E 199795 199820] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-08_01-32-11_890739_199634 is over 95% full, available space: 1.54744 GB; capacity: 95.5616 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-06-08 01:58:03,164 E 199795 199820] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-08_01-32-11_890739_199634 is over 95% full, available space: 1.54752 GB; capacity: 95.5616 GB. Object creation will fail if spilling is required.\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "from typing import Dict, Tuple, Any, Optional\n",
    "\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "\n",
    "\n",
    "# Define your problem using python and Farama-Foundation's gymnasium API:\n",
    "class SimpleCorridor(gym.Env):\n",
    "    \"\"\"Corridor environment where an agent must learn to move right to reach the exit.\n",
    "\n",
    "    ---------------------\n",
    "    | S | 1 | 2 | 3 | G |   S=start; G=goal; corridor_length=5\n",
    "    ---------------------\n",
    "\n",
    "    Actions:\n",
    "        0: Move left\n",
    "        1: Move right\n",
    "\n",
    "    Observations:\n",
    "        A single float representing the agent's current position (index)\n",
    "        starting at 0.0 and ending at corridor_length\n",
    "\n",
    "    Rewards:\n",
    "        -0.1 for each step\n",
    "        +1.0 when reaching the goal\n",
    "\n",
    "    Episode termination:\n",
    "        When the agent reaches the goal (position >= corridor_length)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        self.end_pos = config[\"corridor_length\"]\n",
    "        self.cur_pos = 0.0\n",
    "        self.action_space = gym.spaces.Discrete(2)  # 0=left, 1=right\n",
    "        self.observation_space = gym.spaces.Box(0.0, self.end_pos, (1,), np.float32)\n",
    "\n",
    "    def reset(\n",
    "        self, *, seed: Optional[int] = None, options: Optional[Dict] = None\n",
    "    ) -> Tuple[np.ndarray, Dict]:\n",
    "        \"\"\"Reset the environment for a new episode.\n",
    "\n",
    "        Args:\n",
    "            seed: Random seed for reproducibility\n",
    "            options: Additional options (not used in this environment)\n",
    "\n",
    "        Returns:\n",
    "            Initial observation of the new episode and an info dict.\n",
    "        \"\"\"\n",
    "        super().reset(seed=seed)  # Initialize RNG if seed is provided\n",
    "        self.cur_pos = 0.0\n",
    "        # Return initial observation.\n",
    "        return np.array([self.cur_pos], np.float32), {}\n",
    "\n",
    "    def step(self, action: int) -> Tuple[np.ndarray, float, bool, bool, Dict]:\n",
    "        \"\"\"Take a single step in the environment based on the provided action.\n",
    "\n",
    "        Args:\n",
    "            action: 0 for left, 1 for right\n",
    "\n",
    "        Returns:\n",
    "            A tuple of (observation, reward, terminated, truncated, info):\n",
    "                observation: Agent's new position\n",
    "                reward: Reward from taking the action (-0.1 or +1.0)\n",
    "                terminated: Whether episode is done (reached goal)\n",
    "                truncated: Whether episode was truncated (always False here)\n",
    "                info: Additional information (empty dict)\n",
    "        \"\"\"\n",
    "        # Walk left if action is 0 and we're not at the leftmost position\n",
    "        if action == 0 and self.cur_pos > 0:\n",
    "            self.cur_pos -= 1\n",
    "        # Walk right if action is 1\n",
    "        elif action == 1:\n",
    "            self.cur_pos += 1\n",
    "        # Set `terminated` flag when end of corridor (goal) reached.\n",
    "        terminated = self.cur_pos >= self.end_pos\n",
    "        truncated = False\n",
    "        # +1 when goal reached, otherwise -0.1.\n",
    "        reward = 1.0 if terminated else -0.1\n",
    "        return np.array([self.cur_pos], np.float32), reward, terminated, truncated, {}\n",
    "\n",
    "\n",
    "# Create an RLlib Algorithm instance from a PPOConfig object.\n",
    "print(\"Setting up the PPO configuration...\")\n",
    "config = (\n",
    "    PPOConfig().environment(\n",
    "        # Env class to use (our custom gymnasium environment).\n",
    "        SimpleCorridor,\n",
    "        # Config dict passed to our custom env's constructor.\n",
    "        # Use corridor with 20 fields (including start and goal).\n",
    "        env_config={\"corridor_length\": 20},\n",
    "    )\n",
    "    # Parallelize environment rollouts for faster training.\n",
    "    .env_runners(num_env_runners=3)\n",
    "    # Use a smaller network for this simple task\n",
    "    .training(model={\"fcnet_hiddens\": [64, 64]})\n",
    ")\n",
    "\n",
    "# Construct the actual PPO algorithm object from the config.\n",
    "algo = config.build_algo()\n",
    "rl_module = algo.get_module()\n",
    "\n",
    "# Train for n iterations and report results (mean episode rewards).\n",
    "# Optimal reward calculation:\n",
    "# - Need at least 19 steps to reach the goal (from position 0 to 19)\n",
    "# - Each step (except last) gets -0.1 reward: 18 * (-0.1) = -1.8\n",
    "# - Final step gets +1.0 reward\n",
    "# - Total optimal reward: -1.8 + 1.0 = -0.8\n",
    "print(\"\\nStarting training loop...\")\n",
    "for i in range(5):\n",
    "    results = algo.train()\n",
    "\n",
    "    # Log the metrics from training results\n",
    "    print(f\"Iteration {i+1}\")\n",
    "    print(f\"  Training metrics: {results['env_runners']}\")\n",
    "\n",
    "# Save the trained algorithm (optional)\n",
    "checkpoint_dir = algo.save()\n",
    "print(f\"\\nSaved model checkpoint to: {checkpoint_dir}\")\n",
    "\n",
    "print(\"\\nRunning inference with the trained policy...\")\n",
    "# Create a test environment with a shorter corridor to verify the agent's behavior\n",
    "env = SimpleCorridor({\"corridor_length\": 10})\n",
    "# Get the initial observation (should be: [0.0] for the starting position).\n",
    "obs, info = env.reset()\n",
    "terminated = truncated = False\n",
    "total_reward = 0.0\n",
    "step_count = 0\n",
    "\n",
    "# Play one episode and track the agent's trajectory\n",
    "print(\"\\nAgent trajectory:\")\n",
    "positions = [float(obs[0])]  # Track positions for visualization\n",
    "\n",
    "while not terminated and not truncated:\n",
    "    # Compute an action given the current observation\n",
    "    action_logits = rl_module.forward_inference(\n",
    "        {\"obs\": torch.from_numpy(obs).unsqueeze(0)}\n",
    "    )[\"action_dist_inputs\"].numpy()[\n",
    "        0\n",
    "    ]  # [0]: Batch dimension=1\n",
    "\n",
    "    # Get the action with highest probability\n",
    "    action = np.argmax(action_logits)\n",
    "\n",
    "    # Log the agent's decision\n",
    "    action_name = \"LEFT\" if action == 0 else \"RIGHT\"\n",
    "    print(f\"  Step {step_count}: Position {obs[0]:.1f}, Action: {action_name}\")\n",
    "\n",
    "    # Apply the computed action in the environment\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    positions.append(float(obs[0]))\n",
    "\n",
    "    # Sum up rewards\n",
    "    total_reward += reward\n",
    "    step_count += 1\n",
    "\n",
    "# Report final results\n",
    "print(f\"\\nEpisode complete:\")\n",
    "print(f\"  Steps taken: {step_count}\")\n",
    "print(f\"  Total reward: {total_reward:.2f}\")\n",
    "print(f\"  Final position: {obs[0]:.1f}\")\n",
    "\n",
    "# Verify the agent has learned the optimal policy\n",
    "if total_reward > -0.5 and obs[0] >= 9.0:\n",
    "    print(\"  Success! The agent has learned the optimal policy (always move right).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80917a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 01:38:50,040\tWARNING algorithm_config.py:4856 -- You have specified 1 evaluation workers, but your `evaluation_interval` is 0 or None! Therefore, evaluation doesn't occur automatically with each call to `Algorithm.train()`. Instead, you have to call `Algorithm.evaluate()` manually in order to trigger an evaluation run.\n",
      "/home/brandon-ho/miniconda3/envs/mujoco_env/lib/python3.11/site-packages/ray/rllib/algorithms/algorithm.py:521: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/home/brandon-ho/miniconda3/envs/mujoco_env/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/brandon-ho/miniconda3/envs/mujoco_env/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/brandon-ho/miniconda3/envs/mujoco_env/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "2025-06-08 01:38:52,968\tWARNING algorithm_config.py:4856 -- You have specified 1 evaluation workers, but your `evaluation_interval` is 0 or None! Therefore, evaluation doesn't occur automatically with each call to `Algorithm.train()`. Instead, you have to call `Algorithm.evaluate()` manually in order to trigger an evaluation run.\n",
      "2025-06-08 01:38:55,739\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'config': {'_disable_action_flattening': False,\n",
      "            '_disable_execution_plan_api': -1,\n",
      "            '_disable_initialize_loss_from_dummy_batch': False,\n",
      "            '_disable_preprocessor_api': False,\n",
      "            '_dont_auto_sync_env_runner_states': False,\n",
      "            '_enable_rl_module_api': -1,\n",
      "            '_env_to_module_connector': <function <lambda> at 0x7302b0391d00>,\n",
      "            '_fake_gpus': False,\n",
      "            '_is_atari': None,\n",
      "            '_learner_class': None,\n",
      "            '_learner_connector': None,\n",
      "            '_model_config': {},\n",
      "            '_module_to_env_connector': None,\n",
      "            '_per_module_overrides': {},\n",
      "            '_prior_exploration_config': {'type': 'StochasticSampling'},\n",
      "            '_rl_module_spec': None,\n",
      "            '_tf_policy_handles_more_than_one_loss': False,\n",
      "            '_torch_grad_scaler_class': None,\n",
      "            '_torch_lr_scheduler_classes': None,\n",
      "            '_train_batch_size_per_learner': None,\n",
      "            '_use_msgpack_checkpoints': False,\n",
      "            '_validate_config': True,\n",
      "            'action_mask_key': 'action_mask',\n",
      "            'action_space': None,\n",
      "            'actions_in_input_normalized': False,\n",
      "            'add_default_connectors_to_env_to_module_pipeline': True,\n",
      "            'add_default_connectors_to_learner_pipeline': True,\n",
      "            'add_default_connectors_to_module_to_env_pipeline': True,\n",
      "            'algorithm_config_overrides_per_module': {},\n",
      "            'always_attach_evaluation_results': -1,\n",
      "            'auto_wrap_old_gym_envs': -1,\n",
      "            'batch_mode': 'truncate_episodes',\n",
      "            'broadcast_env_runner_states': True,\n",
      "            'broadcast_offline_eval_runner_states': False,\n",
      "            'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>,\n",
      "            'callbacks_on_algorithm_init': None,\n",
      "            'callbacks_on_checkpoint_loaded': None,\n",
      "            'callbacks_on_env_runners_recreated': None,\n",
      "            'callbacks_on_environment_created': None,\n",
      "            'callbacks_on_episode_created': None,\n",
      "            'callbacks_on_episode_end': None,\n",
      "            'callbacks_on_episode_start': None,\n",
      "            'callbacks_on_episode_step': None,\n",
      "            'callbacks_on_evaluate_end': None,\n",
      "            'callbacks_on_evaluate_offline_end': None,\n",
      "            'callbacks_on_evaluate_offline_start': None,\n",
      "            'callbacks_on_evaluate_start': None,\n",
      "            'callbacks_on_offline_eval_runners_recreated': None,\n",
      "            'callbacks_on_sample_end': None,\n",
      "            'callbacks_on_train_result': None,\n",
      "            'checkpoint_trainable_policies_only': False,\n",
      "            'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>,\n",
      "            'clip_actions': False,\n",
      "            'clip_param': 0.3,\n",
      "            'clip_rewards': None,\n",
      "            'compress_observations': False,\n",
      "            'count_steps_by': 'env_steps',\n",
      "            'create_env_on_driver': False,\n",
      "            'create_local_env_runner': True,\n",
      "            'custom_async_evaluation_function': -1,\n",
      "            'custom_eval_function': None,\n",
      "            'custom_resources_per_env_runner': {},\n",
      "            'custom_resources_per_offline_eval_runner': {},\n",
      "            'dataset_num_iters_per_eval_runner': 1,\n",
      "            'dataset_num_iters_per_learner': None,\n",
      "            'delay_between_env_runner_restarts_s': 60.0,\n",
      "            'disable_env_checking': False,\n",
      "            'eager_max_retraces': 20,\n",
      "            'eager_tracing': True,\n",
      "            'enable_async_evaluation': -1,\n",
      "            'enable_connectors': -1,\n",
      "            'enable_env_runner_and_connector_v2': True,\n",
      "            'enable_rl_module_and_learner': True,\n",
      "            'enable_tf1_exec_eagerly': False,\n",
      "            'entropy_coeff': 0.0,\n",
      "            'entropy_coeff_schedule': None,\n",
      "            'env': 'Taxi-v3',\n",
      "            'env_config': {},\n",
      "            'env_runner_cls': None,\n",
      "            'env_runner_health_probe_timeout_s': 30.0,\n",
      "            'env_runner_restore_timeout_s': 1800.0,\n",
      "            'env_task_fn': -1,\n",
      "            'episode_lookback_horizon': 1,\n",
      "            'episodes_to_numpy': True,\n",
      "            'evaluation_auto_duration_max_env_steps_per_sample': 2000,\n",
      "            'evaluation_auto_duration_min_env_steps_per_sample': 100,\n",
      "            'evaluation_config': None,\n",
      "            'evaluation_duration': 10,\n",
      "            'evaluation_duration_unit': 'episodes',\n",
      "            'evaluation_force_reset_envs_before_iteration': True,\n",
      "            'evaluation_interval': None,\n",
      "            'evaluation_num_env_runners': 1,\n",
      "            'evaluation_parallel_to_training': False,\n",
      "            'evaluation_sample_timeout_s': 120.0,\n",
      "            'exploration_config': {},\n",
      "            'explore': True,\n",
      "            'export_native_model_files': False,\n",
      "            'extra_python_environs_for_driver': {},\n",
      "            'extra_python_environs_for_worker': {},\n",
      "            'fake_sampler': False,\n",
      "            'framework': 'torch',\n",
      "            'gamma': 0.99,\n",
      "            'grad_clip': None,\n",
      "            'grad_clip_by': 'global_norm',\n",
      "            'gym_env_vectorize_mode': 'SYNC',\n",
      "            'ignore_env_runner_failures': False,\n",
      "            'ignore_final_observation': False,\n",
      "            'ignore_offline_eval_runner_failures': False,\n",
      "            'in_evaluation': False,\n",
      "            'input': 'sampler',\n",
      "            'input_compress_columns': ['obs', 'new_obs'],\n",
      "            'input_config': {},\n",
      "            'input_filesystem': None,\n",
      "            'input_filesystem_kwargs': {},\n",
      "            'input_read_batch_size': None,\n",
      "            'input_read_episodes': False,\n",
      "            'input_read_method': 'read_parquet',\n",
      "            'input_read_method_kwargs': {},\n",
      "            'input_read_sample_batches': False,\n",
      "            'input_read_schema': {},\n",
      "            'input_spaces_jsonable': True,\n",
      "            'iter_batches_kwargs': {},\n",
      "            'keep_per_episode_custom_metrics': False,\n",
      "            'kl_coeff': 0.2,\n",
      "            'kl_target': 0.01,\n",
      "            'lambda': 1.0,\n",
      "            'learner_config_dict': {},\n",
      "            'local_gpu_idx': 0,\n",
      "            'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
      "                                      'intra_op_parallelism_threads': 8},\n",
      "            'log_gradients': True,\n",
      "            'log_level': 'WARN',\n",
      "            'log_sys_usage': True,\n",
      "            'logger_config': None,\n",
      "            'logger_creator': None,\n",
      "            'lr': 5e-05,\n",
      "            'lr_schedule': None,\n",
      "            'map_batches_kwargs': {},\n",
      "            'materialize_data': False,\n",
      "            'materialize_mapped_data': True,\n",
      "            'max_num_env_runner_restarts': 1000,\n",
      "            'max_num_offline_eval_runner_restarts': 1000,\n",
      "            'max_requests_in_flight_per_aggregator_actor': 3,\n",
      "            'max_requests_in_flight_per_env_runner': 1,\n",
      "            'max_requests_in_flight_per_learner': 3,\n",
      "            'max_requests_in_flight_per_offline_eval_runner': 1,\n",
      "            'merge_env_runner_states': 'training_only',\n",
      "            'metrics_episode_collection_timeout_s': 60.0,\n",
      "            'metrics_num_episodes_for_smoothing': 100,\n",
      "            'min_sample_timesteps_per_iteration': 0,\n",
      "            'min_time_s_per_iteration': None,\n",
      "            'min_train_timesteps_per_iteration': 0,\n",
      "            'minibatch_size': 128,\n",
      "            'model': {'_disable_action_flattening': False,\n",
      "                      '_disable_preprocessor_api': False,\n",
      "                      '_time_major': False,\n",
      "                      '_use_default_native_models': -1,\n",
      "                      'always_check_shapes': False,\n",
      "                      'attention_dim': 64,\n",
      "                      'attention_head_dim': 32,\n",
      "                      'attention_init_gru_gate_bias': 2.0,\n",
      "                      'attention_memory_inference': 50,\n",
      "                      'attention_memory_training': 50,\n",
      "                      'attention_num_heads': 1,\n",
      "                      'attention_num_transformer_units': 1,\n",
      "                      'attention_position_wise_mlp_dim': 32,\n",
      "                      'attention_use_n_prev_actions': 0,\n",
      "                      'attention_use_n_prev_rewards': 0,\n",
      "                      'conv_activation': 'relu',\n",
      "                      'conv_bias_initializer': None,\n",
      "                      'conv_bias_initializer_config': None,\n",
      "                      'conv_filters': None,\n",
      "                      'conv_kernel_initializer': None,\n",
      "                      'conv_kernel_initializer_config': None,\n",
      "                      'conv_transpose_bias_initializer': None,\n",
      "                      'conv_transpose_bias_initializer_config': None,\n",
      "                      'conv_transpose_kernel_initializer': None,\n",
      "                      'conv_transpose_kernel_initializer_config': None,\n",
      "                      'custom_action_dist': None,\n",
      "                      'custom_model': None,\n",
      "                      'custom_model_config': {},\n",
      "                      'custom_preprocessor': None,\n",
      "                      'dim': 84,\n",
      "                      'encoder_latent_dim': None,\n",
      "                      'fcnet_activation': 'tanh',\n",
      "                      'fcnet_bias_initializer': None,\n",
      "                      'fcnet_bias_initializer_config': None,\n",
      "                      'fcnet_hiddens': [256, 256],\n",
      "                      'fcnet_weights_initializer': None,\n",
      "                      'fcnet_weights_initializer_config': None,\n",
      "                      'framestack': True,\n",
      "                      'free_log_std': False,\n",
      "                      'grayscale': False,\n",
      "                      'log_std_clip_param': 20.0,\n",
      "                      'lstm_bias_initializer': None,\n",
      "                      'lstm_bias_initializer_config': None,\n",
      "                      'lstm_cell_size': 256,\n",
      "                      'lstm_use_prev_action': False,\n",
      "                      'lstm_use_prev_action_reward': -1,\n",
      "                      'lstm_use_prev_reward': False,\n",
      "                      'lstm_weights_initializer': None,\n",
      "                      'lstm_weights_initializer_config': None,\n",
      "                      'max_seq_len': 20,\n",
      "                      'no_final_linear': False,\n",
      "                      'post_fcnet_activation': 'relu',\n",
      "                      'post_fcnet_bias_initializer': None,\n",
      "                      'post_fcnet_bias_initializer_config': None,\n",
      "                      'post_fcnet_hiddens': [],\n",
      "                      'post_fcnet_weights_initializer': None,\n",
      "                      'post_fcnet_weights_initializer_config': None,\n",
      "                      'use_attention': False,\n",
      "                      'use_lstm': False,\n",
      "                      'vf_share_layers': False,\n",
      "                      'zero_mean': True},\n",
      "            'normalize_actions': True,\n",
      "            'num_aggregator_actors_per_learner': 0,\n",
      "            'num_consecutive_env_runner_failures_tolerance': 100,\n",
      "            'num_cpus_for_main_process': 1,\n",
      "            'num_cpus_per_env_runner': 1,\n",
      "            'num_cpus_per_learner': 'auto',\n",
      "            'num_cpus_per_offline_eval_runner': 1,\n",
      "            'num_env_runners': 2,\n",
      "            'num_envs_per_env_runner': 1,\n",
      "            'num_epochs': 30,\n",
      "            'num_gpus': 0,\n",
      "            'num_gpus_per_env_runner': 0,\n",
      "            'num_gpus_per_learner': 0,\n",
      "            'num_gpus_per_offline_eval_runner': 0,\n",
      "            'num_learners': 0,\n",
      "            'num_offline_eval_runners': 0,\n",
      "            'observation_filter': 'NoFilter',\n",
      "            'observation_fn': None,\n",
      "            'observation_space': None,\n",
      "            'off_policy_estimation_methods': {},\n",
      "            'offline_data_class': None,\n",
      "            'offline_eval_batch_size_per_runner': 256,\n",
      "            'offline_eval_rl_module_inference_only': False,\n",
      "            'offline_eval_runner_health_probe_timeout_s': 30.0,\n",
      "            'offline_eval_runner_restore_timeout_s': 1800.0,\n",
      "            'offline_evaluation_duration': 1,\n",
      "            'offline_evaluation_interval': None,\n",
      "            'offline_evaluation_parallel_to_training': False,\n",
      "            'offline_evaluation_timeout_s': 120.0,\n",
      "            'offline_loss_for_module_fn': None,\n",
      "            'offline_sampling': False,\n",
      "            'ope_split_batch_by_episode': True,\n",
      "            'optimizer': {},\n",
      "            'output': None,\n",
      "            'output_compress_columns': ['obs', 'new_obs'],\n",
      "            'output_config': {},\n",
      "            'output_filesystem': None,\n",
      "            'output_filesystem_kwargs': {},\n",
      "            'output_max_file_size': 67108864,\n",
      "            'output_max_rows_per_file': None,\n",
      "            'output_write_episodes': True,\n",
      "            'output_write_method': 'write_parquet',\n",
      "            'output_write_method_kwargs': {},\n",
      "            'output_write_remaining_data': False,\n",
      "            'placement_strategy': 'PACK',\n",
      "            'policies': {'default_policy': (None, None, None, None)},\n",
      "            'policies_to_train': None,\n",
      "            'policy_map_cache': -1,\n",
      "            'policy_map_capacity': 100,\n",
      "            'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x730510b16840>,\n",
      "            'policy_states_are_swappable': False,\n",
      "            'postprocess_inputs': False,\n",
      "            'prelearner_buffer_class': None,\n",
      "            'prelearner_buffer_kwargs': {},\n",
      "            'prelearner_class': None,\n",
      "            'prelearner_module_synch_period': 10,\n",
      "            'preprocessor_pref': 'deepmind',\n",
      "            'remote_env_batch_wait_ms': 0,\n",
      "            'remote_worker_envs': False,\n",
      "            'render_env': False,\n",
      "            'replay_sequence_length': None,\n",
      "            'restart_failed_env_runners': True,\n",
      "            'restart_failed_offline_eval_runners': True,\n",
      "            'restart_failed_sub_environments': False,\n",
      "            'rollout_fragment_length': 'auto',\n",
      "            'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
      "            'sample_timeout_s': 60.0,\n",
      "            'sampler_perf_stats_ema_coef': None,\n",
      "            'seed': None,\n",
      "            'sgd_minibatch_size': -1,\n",
      "            'shuffle_batch_per_epoch': True,\n",
      "            'shuffle_buffer_size': 0,\n",
      "            'simple_optimizer': False,\n",
      "            'sync_filters_on_rollout_workers_timeout_s': 10.0,\n",
      "            'synchronize_filters': -1,\n",
      "            'tf_session_args': {'allow_soft_placement': True,\n",
      "                                'device_count': {'CPU': 1},\n",
      "                                'gpu_options': {'allow_growth': True},\n",
      "                                'inter_op_parallelism_threads': 2,\n",
      "                                'intra_op_parallelism_threads': 2,\n",
      "                                'log_device_placement': False},\n",
      "            'torch_compile_learner': False,\n",
      "            'torch_compile_learner_dynamo_backend': 'inductor',\n",
      "            'torch_compile_learner_dynamo_mode': None,\n",
      "            'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>,\n",
      "            'torch_compile_worker': False,\n",
      "            'torch_compile_worker_dynamo_backend': 'onnxrt',\n",
      "            'torch_compile_worker_dynamo_mode': None,\n",
      "            'torch_ddp_kwargs': {},\n",
      "            'torch_skip_nan_gradients': False,\n",
      "            'train_batch_size': 4000,\n",
      "            'update_worker_filter_stats': True,\n",
      "            'use_critic': True,\n",
      "            'use_gae': True,\n",
      "            'use_kl_loss': True,\n",
      "            'use_worker_filter_stats': True,\n",
      "            'validate_env_runners_after_construction': True,\n",
      "            'validate_offline_eval_runners_after_construction': True,\n",
      "            'vf_clip_param': 10.0,\n",
      "            'vf_loss_coeff': 1.0,\n",
      "            'vf_share_layers': -1,\n",
      "            'worker_cls': -1},\n",
      " 'date': '2025-06-08_01-39-04',\n",
      " 'done': False,\n",
      " 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0},\n",
      " 'env_runners': {'agent_episode_returns_mean': {'default_agent': -760.1},\n",
      "                 'env_reset_timer': np.float64(0.00033987000642810017),\n",
      "                 'env_step_timer': np.float64(7.496650696172844e-05),\n",
      "                 'env_to_module_connector': {'connector_pipeline_timer': np.float64(0.00017850994703541874),\n",
      "                                             'timers': {'connectors': {'add_observations_from_episodes_to_batch': np.float64(7.558569009245588e-06),\n",
      "                                                                       'add_states_from_episodes_to_batch': np.float64(4.281988622572203e-06),\n",
      "                                                                       'add_time_dim_to_batch_and_zero_pad': np.float64(7.16139954459514e-06),\n",
      "                                                                       'batch_individual_items': np.float64(2.067111827996636e-05),\n",
      "                                                                       'flatten_observations': np.float64(4.703314246853349e-05),\n",
      "                                                                       'numpy_to_tensor': np.float64(3.5522808399616836e-05)}}},\n",
      "                 'env_to_module_sum_episodes_length_in': np.float64(131.73765398537716),\n",
      "                 'env_to_module_sum_episodes_length_out': np.float64(131.73765398537716),\n",
      "                 'episode_duration_sec_mean': 0.18265918424731353,\n",
      "                 'episode_len_max': 200,\n",
      "                 'episode_len_mean': 200.0,\n",
      "                 'episode_len_min': 200,\n",
      "                 'episode_return_max': -605.0,\n",
      "                 'episode_return_mean': -760.1,\n",
      "                 'episode_return_min': -929.0,\n",
      "                 'module_episode_returns_mean': {'default_policy': -760.1},\n",
      "                 'module_to_env_connector': {'connector_pipeline_timer': np.float64(0.0003849165579656308),\n",
      "                                             'timers': {'connectors': {'get_actions': np.float64(0.00018504111175419302),\n",
      "                                                                       'listify_data_for_vector_env': np.float64(3.451193763194208e-05),\n",
      "                                                                       'normalize_and_clip_actions': np.float64(2.9305147186723494e-05),\n",
      "                                                                       'remove_single_ts_time_rank_from_batch': np.float64(1.9375320828367455e-06),\n",
      "                                                                       'tensor_to_numpy': np.float64(5.240769809747783e-05),\n",
      "                                                                       'un_batch_to_individual_items': np.float64(1.6897908316905917e-05)}}},\n",
      "                 'num_agent_steps_sampled': {'default_agent': 4000},\n",
      "                 'num_agent_steps_sampled_lifetime': {'default_agent': 4000},\n",
      "                 'num_env_steps_sampled': 4000,\n",
      "                 'num_env_steps_sampled_lifetime': 4000,\n",
      "                 'num_env_steps_sampled_lifetime_throughput': nan,\n",
      "                 'num_episodes': 20,\n",
      "                 'num_episodes_lifetime': 20,\n",
      "                 'num_module_steps_sampled': {'default_policy': 4000},\n",
      "                 'num_module_steps_sampled_lifetime': {'default_policy': 4000},\n",
      "                 'rlmodule_inference_timer': np.float64(0.00014317323859060595),\n",
      "                 'sample': np.float64(1.858987186482409),\n",
      "                 'weights_seq_no': 0.0},\n",
      " 'fault_tolerance': {'num_healthy_workers': 2, 'num_remote_worker_restarts': 0},\n",
      " 'hostname': 'brandon-ho-OMEN-by-HP-Laptop-15-dc0xxx',\n",
      " 'iterations_since_restore': 1,\n",
      " 'learners': {'__all_modules__': {'learner_connector': {'connector_pipeline_timer': 0.16967891799868084,\n",
      "                                                        'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.06780402001459152,\n",
      "                                                                                  'add_observations_from_episodes_to_batch': 0.00029103000997565687,\n",
      "                                                                                  'add_one_ts_to_episodes_and_truncate': 0.008628668001620099,\n",
      "                                                                                  'add_states_from_episodes_to_batch': 7.534021278843284e-06,\n",
      "                                                                                  'add_time_dim_to_batch_and_zero_pad': 2.280602348037064e-05,\n",
      "                                                                                  'batch_individual_items': 0.050029746984364465,\n",
      "                                                                                  'general_advantage_estimation': 0.04243192099966109,\n",
      "                                                                                  'numpy_to_tensor': 0.00015548599185422063}}},\n",
      "                                  'learner_connector_sum_episodes_length_in': 4000,\n",
      "                                  'learner_connector_sum_episodes_length_out': 4020,\n",
      "                                  'num_env_steps_trained': 3790860,\n",
      "                                  'num_env_steps_trained_lifetime': 3790860,\n",
      "                                  'num_env_steps_trained_lifetime_throughput': nan,\n",
      "                                  'num_module_steps_trained': 120704,\n",
      "                                  'num_module_steps_trained_lifetime': 120704,\n",
      "                                  'num_non_trainable_parameters': 0,\n",
      "                                  'num_trainable_parameters': 389895},\n",
      "              'default_policy': {'curr_entropy_coeff': 0.0,\n",
      "                                 'curr_kl_coeff': 0.20000000298023224,\n",
      "                                 'default_optimizer_learning_rate': 5e-05,\n",
      "                                 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0),\n",
      "                                 'entropy': np.float32(1.7746961),\n",
      "                                 'gradients_default_optimizer_global_norm': np.float32(0.15197624),\n",
      "                                 'mean_kl_loss': np.float32(0.015039133),\n",
      "                                 'module_train_batch_size_mean': 128.0,\n",
      "                                 'num_module_steps_trained': 120704,\n",
      "                                 'num_module_steps_trained_lifetime': 120704,\n",
      "                                 'num_trainable_parameters': 389895,\n",
      "                                 'policy_loss': np.float32(0.10286473),\n",
      "                                 'total_loss': np.float32(10.105873),\n",
      "                                 'vf_explained_var': np.float32(-0.00015950203),\n",
      "                                 'vf_loss': np.float32(10.0),\n",
      "                                 'vf_loss_unclipped': np.float32(60068.406),\n",
      "                                 'weights_seq_no': 1.0}},\n",
      " 'node_ip': '192.168.0.18',\n",
      " 'num_env_steps_sampled_lifetime': 4000,\n",
      " 'num_env_steps_sampled_lifetime_throughput': nan,\n",
      " 'num_training_step_calls_per_iteration': 1,\n",
      " 'perf': {'cpu_util_percent': np.float64(43.400000000000006),\n",
      "          'ram_util_percent': np.float64(33.884615384615394)},\n",
      " 'pid': 199634,\n",
      " 'time_since_restore': 9.00296926498413,\n",
      " 'time_this_iter_s': 9.00296926498413,\n",
      " 'time_total_s': 9.00296926498413,\n",
      " 'timers': {'env_runner_sampling_timer': 2.0312155559950043,\n",
      "            'learner_update_timer': 6.960460145986872,\n",
      "            'restore_env_runners': 1.992701436392963e-05,\n",
      "            'synch_weights': 0.0021601709886454046,\n",
      "            'training_iteration': 8.996118545997888,\n",
      "            'training_step': 8.995884645002661},\n",
      " 'timestamp': 1749361144,\n",
      " 'training_iteration': 1,\n",
      " 'trial_id': 'default'}\n",
      "{'config': {'_disable_action_flattening': False,\n",
      "            '_disable_execution_plan_api': -1,\n",
      "            '_disable_initialize_loss_from_dummy_batch': False,\n",
      "            '_disable_preprocessor_api': False,\n",
      "            '_dont_auto_sync_env_runner_states': False,\n",
      "            '_enable_rl_module_api': -1,\n",
      "            '_env_to_module_connector': <function <lambda> at 0x7302b0391d00>,\n",
      "            '_fake_gpus': False,\n",
      "            '_is_atari': None,\n",
      "            '_learner_class': None,\n",
      "            '_learner_connector': None,\n",
      "            '_model_config': {},\n",
      "            '_module_to_env_connector': None,\n",
      "            '_per_module_overrides': {},\n",
      "            '_prior_exploration_config': {'type': 'StochasticSampling'},\n",
      "            '_rl_module_spec': None,\n",
      "            '_tf_policy_handles_more_than_one_loss': False,\n",
      "            '_torch_grad_scaler_class': None,\n",
      "            '_torch_lr_scheduler_classes': None,\n",
      "            '_train_batch_size_per_learner': None,\n",
      "            '_use_msgpack_checkpoints': False,\n",
      "            '_validate_config': True,\n",
      "            'action_mask_key': 'action_mask',\n",
      "            'action_space': None,\n",
      "            'actions_in_input_normalized': False,\n",
      "            'add_default_connectors_to_env_to_module_pipeline': True,\n",
      "            'add_default_connectors_to_learner_pipeline': True,\n",
      "            'add_default_connectors_to_module_to_env_pipeline': True,\n",
      "            'algorithm_config_overrides_per_module': {},\n",
      "            'always_attach_evaluation_results': -1,\n",
      "            'auto_wrap_old_gym_envs': -1,\n",
      "            'batch_mode': 'truncate_episodes',\n",
      "            'broadcast_env_runner_states': True,\n",
      "            'broadcast_offline_eval_runner_states': False,\n",
      "            'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>,\n",
      "            'callbacks_on_algorithm_init': None,\n",
      "            'callbacks_on_checkpoint_loaded': None,\n",
      "            'callbacks_on_env_runners_recreated': None,\n",
      "            'callbacks_on_environment_created': None,\n",
      "            'callbacks_on_episode_created': None,\n",
      "            'callbacks_on_episode_end': None,\n",
      "            'callbacks_on_episode_start': None,\n",
      "            'callbacks_on_episode_step': None,\n",
      "            'callbacks_on_evaluate_end': None,\n",
      "            'callbacks_on_evaluate_offline_end': None,\n",
      "            'callbacks_on_evaluate_offline_start': None,\n",
      "            'callbacks_on_evaluate_start': None,\n",
      "            'callbacks_on_offline_eval_runners_recreated': None,\n",
      "            'callbacks_on_sample_end': None,\n",
      "            'callbacks_on_train_result': None,\n",
      "            'checkpoint_trainable_policies_only': False,\n",
      "            'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>,\n",
      "            'clip_actions': False,\n",
      "            'clip_param': 0.3,\n",
      "            'clip_rewards': None,\n",
      "            'compress_observations': False,\n",
      "            'count_steps_by': 'env_steps',\n",
      "            'create_env_on_driver': False,\n",
      "            'create_local_env_runner': True,\n",
      "            'custom_async_evaluation_function': -1,\n",
      "            'custom_eval_function': None,\n",
      "            'custom_resources_per_env_runner': {},\n",
      "            'custom_resources_per_offline_eval_runner': {},\n",
      "            'dataset_num_iters_per_eval_runner': 1,\n",
      "            'dataset_num_iters_per_learner': None,\n",
      "            'delay_between_env_runner_restarts_s': 60.0,\n",
      "            'disable_env_checking': False,\n",
      "            'eager_max_retraces': 20,\n",
      "            'eager_tracing': True,\n",
      "            'enable_async_evaluation': -1,\n",
      "            'enable_connectors': -1,\n",
      "            'enable_env_runner_and_connector_v2': True,\n",
      "            'enable_rl_module_and_learner': True,\n",
      "            'enable_tf1_exec_eagerly': False,\n",
      "            'entropy_coeff': 0.0,\n",
      "            'entropy_coeff_schedule': None,\n",
      "            'env': 'Taxi-v3',\n",
      "            'env_config': {},\n",
      "            'env_runner_cls': None,\n",
      "            'env_runner_health_probe_timeout_s': 30.0,\n",
      "            'env_runner_restore_timeout_s': 1800.0,\n",
      "            'env_task_fn': -1,\n",
      "            'episode_lookback_horizon': 1,\n",
      "            'episodes_to_numpy': True,\n",
      "            'evaluation_auto_duration_max_env_steps_per_sample': 2000,\n",
      "            'evaluation_auto_duration_min_env_steps_per_sample': 100,\n",
      "            'evaluation_config': None,\n",
      "            'evaluation_duration': 10,\n",
      "            'evaluation_duration_unit': 'episodes',\n",
      "            'evaluation_force_reset_envs_before_iteration': True,\n",
      "            'evaluation_interval': None,\n",
      "            'evaluation_num_env_runners': 1,\n",
      "            'evaluation_parallel_to_training': False,\n",
      "            'evaluation_sample_timeout_s': 120.0,\n",
      "            'exploration_config': {},\n",
      "            'explore': True,\n",
      "            'export_native_model_files': False,\n",
      "            'extra_python_environs_for_driver': {},\n",
      "            'extra_python_environs_for_worker': {},\n",
      "            'fake_sampler': False,\n",
      "            'framework': 'torch',\n",
      "            'gamma': 0.99,\n",
      "            'grad_clip': None,\n",
      "            'grad_clip_by': 'global_norm',\n",
      "            'gym_env_vectorize_mode': 'SYNC',\n",
      "            'ignore_env_runner_failures': False,\n",
      "            'ignore_final_observation': False,\n",
      "            'ignore_offline_eval_runner_failures': False,\n",
      "            'in_evaluation': False,\n",
      "            'input': 'sampler',\n",
      "            'input_compress_columns': ['obs', 'new_obs'],\n",
      "            'input_config': {},\n",
      "            'input_filesystem': None,\n",
      "            'input_filesystem_kwargs': {},\n",
      "            'input_read_batch_size': None,\n",
      "            'input_read_episodes': False,\n",
      "            'input_read_method': 'read_parquet',\n",
      "            'input_read_method_kwargs': {},\n",
      "            'input_read_sample_batches': False,\n",
      "            'input_read_schema': {},\n",
      "            'input_spaces_jsonable': True,\n",
      "            'iter_batches_kwargs': {},\n",
      "            'keep_per_episode_custom_metrics': False,\n",
      "            'kl_coeff': 0.2,\n",
      "            'kl_target': 0.01,\n",
      "            'lambda': 1.0,\n",
      "            'learner_config_dict': {},\n",
      "            'local_gpu_idx': 0,\n",
      "            'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
      "                                      'intra_op_parallelism_threads': 8},\n",
      "            'log_gradients': True,\n",
      "            'log_level': 'WARN',\n",
      "            'log_sys_usage': True,\n",
      "            'logger_config': None,\n",
      "            'logger_creator': None,\n",
      "            'lr': 5e-05,\n",
      "            'lr_schedule': None,\n",
      "            'map_batches_kwargs': {},\n",
      "            'materialize_data': False,\n",
      "            'materialize_mapped_data': True,\n",
      "            'max_num_env_runner_restarts': 1000,\n",
      "            'max_num_offline_eval_runner_restarts': 1000,\n",
      "            'max_requests_in_flight_per_aggregator_actor': 3,\n",
      "            'max_requests_in_flight_per_env_runner': 1,\n",
      "            'max_requests_in_flight_per_learner': 3,\n",
      "            'max_requests_in_flight_per_offline_eval_runner': 1,\n",
      "            'merge_env_runner_states': 'training_only',\n",
      "            'metrics_episode_collection_timeout_s': 60.0,\n",
      "            'metrics_num_episodes_for_smoothing': 100,\n",
      "            'min_sample_timesteps_per_iteration': 0,\n",
      "            'min_time_s_per_iteration': None,\n",
      "            'min_train_timesteps_per_iteration': 0,\n",
      "            'minibatch_size': 128,\n",
      "            'model': {'_disable_action_flattening': False,\n",
      "                      '_disable_preprocessor_api': False,\n",
      "                      '_time_major': False,\n",
      "                      '_use_default_native_models': -1,\n",
      "                      'always_check_shapes': False,\n",
      "                      'attention_dim': 64,\n",
      "                      'attention_head_dim': 32,\n",
      "                      'attention_init_gru_gate_bias': 2.0,\n",
      "                      'attention_memory_inference': 50,\n",
      "                      'attention_memory_training': 50,\n",
      "                      'attention_num_heads': 1,\n",
      "                      'attention_num_transformer_units': 1,\n",
      "                      'attention_position_wise_mlp_dim': 32,\n",
      "                      'attention_use_n_prev_actions': 0,\n",
      "                      'attention_use_n_prev_rewards': 0,\n",
      "                      'conv_activation': 'relu',\n",
      "                      'conv_bias_initializer': None,\n",
      "                      'conv_bias_initializer_config': None,\n",
      "                      'conv_filters': None,\n",
      "                      'conv_kernel_initializer': None,\n",
      "                      'conv_kernel_initializer_config': None,\n",
      "                      'conv_transpose_bias_initializer': None,\n",
      "                      'conv_transpose_bias_initializer_config': None,\n",
      "                      'conv_transpose_kernel_initializer': None,\n",
      "                      'conv_transpose_kernel_initializer_config': None,\n",
      "                      'custom_action_dist': None,\n",
      "                      'custom_model': None,\n",
      "                      'custom_model_config': {},\n",
      "                      'custom_preprocessor': None,\n",
      "                      'dim': 84,\n",
      "                      'encoder_latent_dim': None,\n",
      "                      'fcnet_activation': 'tanh',\n",
      "                      'fcnet_bias_initializer': None,\n",
      "                      'fcnet_bias_initializer_config': None,\n",
      "                      'fcnet_hiddens': [256, 256],\n",
      "                      'fcnet_weights_initializer': None,\n",
      "                      'fcnet_weights_initializer_config': None,\n",
      "                      'framestack': True,\n",
      "                      'free_log_std': False,\n",
      "                      'grayscale': False,\n",
      "                      'log_std_clip_param': 20.0,\n",
      "                      'lstm_bias_initializer': None,\n",
      "                      'lstm_bias_initializer_config': None,\n",
      "                      'lstm_cell_size': 256,\n",
      "                      'lstm_use_prev_action': False,\n",
      "                      'lstm_use_prev_action_reward': -1,\n",
      "                      'lstm_use_prev_reward': False,\n",
      "                      'lstm_weights_initializer': None,\n",
      "                      'lstm_weights_initializer_config': None,\n",
      "                      'max_seq_len': 20,\n",
      "                      'no_final_linear': False,\n",
      "                      'post_fcnet_activation': 'relu',\n",
      "                      'post_fcnet_bias_initializer': None,\n",
      "                      'post_fcnet_bias_initializer_config': None,\n",
      "                      'post_fcnet_hiddens': [],\n",
      "                      'post_fcnet_weights_initializer': None,\n",
      "                      'post_fcnet_weights_initializer_config': None,\n",
      "                      'use_attention': False,\n",
      "                      'use_lstm': False,\n",
      "                      'vf_share_layers': False,\n",
      "                      'zero_mean': True},\n",
      "            'normalize_actions': True,\n",
      "            'num_aggregator_actors_per_learner': 0,\n",
      "            'num_consecutive_env_runner_failures_tolerance': 100,\n",
      "            'num_cpus_for_main_process': 1,\n",
      "            'num_cpus_per_env_runner': 1,\n",
      "            'num_cpus_per_learner': 'auto',\n",
      "            'num_cpus_per_offline_eval_runner': 1,\n",
      "            'num_env_runners': 2,\n",
      "            'num_envs_per_env_runner': 1,\n",
      "            'num_epochs': 30,\n",
      "            'num_gpus': 0,\n",
      "            'num_gpus_per_env_runner': 0,\n",
      "            'num_gpus_per_learner': 0,\n",
      "            'num_gpus_per_offline_eval_runner': 0,\n",
      "            'num_learners': 0,\n",
      "            'num_offline_eval_runners': 0,\n",
      "            'observation_filter': 'NoFilter',\n",
      "            'observation_fn': None,\n",
      "            'observation_space': None,\n",
      "            'off_policy_estimation_methods': {},\n",
      "            'offline_data_class': None,\n",
      "            'offline_eval_batch_size_per_runner': 256,\n",
      "            'offline_eval_rl_module_inference_only': False,\n",
      "            'offline_eval_runner_health_probe_timeout_s': 30.0,\n",
      "            'offline_eval_runner_restore_timeout_s': 1800.0,\n",
      "            'offline_evaluation_duration': 1,\n",
      "            'offline_evaluation_interval': None,\n",
      "            'offline_evaluation_parallel_to_training': False,\n",
      "            'offline_evaluation_timeout_s': 120.0,\n",
      "            'offline_loss_for_module_fn': None,\n",
      "            'offline_sampling': False,\n",
      "            'ope_split_batch_by_episode': True,\n",
      "            'optimizer': {},\n",
      "            'output': None,\n",
      "            'output_compress_columns': ['obs', 'new_obs'],\n",
      "            'output_config': {},\n",
      "            'output_filesystem': None,\n",
      "            'output_filesystem_kwargs': {},\n",
      "            'output_max_file_size': 67108864,\n",
      "            'output_max_rows_per_file': None,\n",
      "            'output_write_episodes': True,\n",
      "            'output_write_method': 'write_parquet',\n",
      "            'output_write_method_kwargs': {},\n",
      "            'output_write_remaining_data': False,\n",
      "            'placement_strategy': 'PACK',\n",
      "            'policies': {'default_policy': (None, None, None, None)},\n",
      "            'policies_to_train': None,\n",
      "            'policy_map_cache': -1,\n",
      "            'policy_map_capacity': 100,\n",
      "            'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x730510b16840>,\n",
      "            'policy_states_are_swappable': False,\n",
      "            'postprocess_inputs': False,\n",
      "            'prelearner_buffer_class': None,\n",
      "            'prelearner_buffer_kwargs': {},\n",
      "            'prelearner_class': None,\n",
      "            'prelearner_module_synch_period': 10,\n",
      "            'preprocessor_pref': 'deepmind',\n",
      "            'remote_env_batch_wait_ms': 0,\n",
      "            'remote_worker_envs': False,\n",
      "            'render_env': False,\n",
      "            'replay_sequence_length': None,\n",
      "            'restart_failed_env_runners': True,\n",
      "            'restart_failed_offline_eval_runners': True,\n",
      "            'restart_failed_sub_environments': False,\n",
      "            'rollout_fragment_length': 'auto',\n",
      "            'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
      "            'sample_timeout_s': 60.0,\n",
      "            'sampler_perf_stats_ema_coef': None,\n",
      "            'seed': None,\n",
      "            'sgd_minibatch_size': -1,\n",
      "            'shuffle_batch_per_epoch': True,\n",
      "            'shuffle_buffer_size': 0,\n",
      "            'simple_optimizer': False,\n",
      "            'sync_filters_on_rollout_workers_timeout_s': 10.0,\n",
      "            'synchronize_filters': -1,\n",
      "            'tf_session_args': {'allow_soft_placement': True,\n",
      "                                'device_count': {'CPU': 1},\n",
      "                                'gpu_options': {'allow_growth': True},\n",
      "                                'inter_op_parallelism_threads': 2,\n",
      "                                'intra_op_parallelism_threads': 2,\n",
      "                                'log_device_placement': False},\n",
      "            'torch_compile_learner': False,\n",
      "            'torch_compile_learner_dynamo_backend': 'inductor',\n",
      "            'torch_compile_learner_dynamo_mode': None,\n",
      "            'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>,\n",
      "            'torch_compile_worker': False,\n",
      "            'torch_compile_worker_dynamo_backend': 'onnxrt',\n",
      "            'torch_compile_worker_dynamo_mode': None,\n",
      "            'torch_ddp_kwargs': {},\n",
      "            'torch_skip_nan_gradients': False,\n",
      "            'train_batch_size': 4000,\n",
      "            'update_worker_filter_stats': True,\n",
      "            'use_critic': True,\n",
      "            'use_gae': True,\n",
      "            'use_kl_loss': True,\n",
      "            'use_worker_filter_stats': True,\n",
      "            'validate_env_runners_after_construction': True,\n",
      "            'validate_offline_eval_runners_after_construction': True,\n",
      "            'vf_clip_param': 10.0,\n",
      "            'vf_loss_coeff': 1.0,\n",
      "            'vf_share_layers': -1,\n",
      "            'worker_cls': -1},\n",
      " 'date': '2025-06-08_01-39-13',\n",
      " 'done': False,\n",
      " 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0},\n",
      " 'env_runners': {'agent_episode_returns_mean': {'default_agent': -718.24},\n",
      "                 'env_reset_timer': np.float64(0.00033987000642810017),\n",
      "                 'env_step_timer': np.float64(7.507332116700474e-05),\n",
      "                 'env_to_module_connector': {'connector_pipeline_timer': np.float64(0.0001788196280712571),\n",
      "                                             'timers': {'connectors': {'add_observations_from_episodes_to_batch': np.float64(7.569070105844751e-06),\n",
      "                                                                       'add_states_from_episodes_to_batch': np.float64(4.289415595047993e-06),\n",
      "                                                                       'add_time_dim_to_batch_and_zero_pad': np.float64(7.175307153196629e-06),\n",
      "                                                                       'batch_individual_items': np.float64(2.070036146174724e-05),\n",
      "                                                                       'flatten_observations': np.float64(4.708782997925396e-05),\n",
      "                                                                       'numpy_to_tensor': np.float64(3.558579402082285e-05)}}},\n",
      "                 'env_to_module_sum_episodes_length_in': np.float64(131.51277839402354),\n",
      "                 'env_to_module_sum_episodes_length_out': np.float64(131.51277839402354),\n",
      "                 'episode_duration_sec_mean': 0.179040946920868,\n",
      "                 'episode_len_max': 200,\n",
      "                 'episode_len_mean': 196.72,\n",
      "                 'episode_len_min': 36,\n",
      "                 'episode_return_max': -105.0,\n",
      "                 'episode_return_mean': -718.24,\n",
      "                 'episode_return_min': -929.0,\n",
      "                 'module_episode_returns_mean': {'default_policy': -718.24},\n",
      "                 'module_to_env_connector': {'connector_pipeline_timer': np.float64(0.00038555518227938054),\n",
      "                                             'timers': {'connectors': {'get_actions': np.float64(0.00018533599300073994),\n",
      "                                                                       'listify_data_for_vector_env': np.float64(3.455121858812052e-05),\n",
      "                                                                       'normalize_and_clip_actions': np.float64(2.934811059416519e-05),\n",
      "                                                                       'remove_single_ts_time_rank_from_batch': np.float64(1.9428142364531442e-06),\n",
      "                                                                       'tensor_to_numpy': np.float64(5.2510951499730206e-05),\n",
      "                                                                       'un_batch_to_individual_items': np.float64(1.6929775339385617e-05)}}},\n",
      "                 'num_agent_steps_sampled': {'default_agent': 4000},\n",
      "                 'num_agent_steps_sampled_lifetime': {'default_agent': 8000},\n",
      "                 'num_env_steps_sampled': 4000,\n",
      "                 'num_env_steps_sampled_lifetime': 8000,\n",
      "                 'num_env_steps_sampled_lifetime_throughput': 433.2683885169485,\n",
      "                 'num_episodes': 20,\n",
      "                 'num_episodes_lifetime': 40,\n",
      "                 'num_module_steps_sampled': {'default_policy': 4000},\n",
      "                 'num_module_steps_sampled_lifetime': {'default_policy': 8000},\n",
      "                 'rlmodule_inference_timer': np.float64(0.00014345525612849584),\n",
      "                 'sample': np.float64(1.8589885689775003),\n",
      "                 'time_between_sampling': np.float64(7.167949546492309),\n",
      "                 'weights_seq_no': 1.0},\n",
      " 'fault_tolerance': {'num_healthy_workers': 2, 'num_remote_worker_restarts': 0},\n",
      " 'hostname': 'brandon-ho-OMEN-by-HP-Laptop-15-dc0xxx',\n",
      " 'iterations_since_restore': 2,\n",
      " 'learners': {'__all_modules__': {'learner_connector': {'connector_pipeline_timer': 0.1696753039769799,\n",
      "                                                        'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.0678031473442912,\n",
      "                                                                                  'add_observations_from_episodes_to_batch': 0.00029101830527361014,\n",
      "                                                                                  'add_one_ts_to_episodes_and_truncate': 0.008628237716719741,\n",
      "                                                                                  'add_states_from_episodes_to_batch': 7.534801578731276e-06,\n",
      "                                                                                  'add_time_dim_to_batch_and_zero_pad': 2.2806375878280962e-05,\n",
      "                                                                                  'batch_individual_items': 0.05003019061296654,\n",
      "                                                                                  'general_advantage_estimation': 0.042429188880560104,\n",
      "                                                                                  'numpy_to_tensor': 0.0001554865897545824}}},\n",
      "                                  'learner_connector_sum_episodes_length_in': 4000.0,\n",
      "                                  'learner_connector_sum_episodes_length_out': 4020.0001,\n",
      "                                  'num_env_steps_trained': 3791803,\n",
      "                                  'num_env_steps_trained_lifetime': 7582663,\n",
      "                                  'num_env_steps_trained_lifetime_throughput': 0.0,\n",
      "                                  'num_module_steps_trained': 120704,\n",
      "                                  'num_module_steps_trained_lifetime': 241408,\n",
      "                                  'num_non_trainable_parameters': 0.0,\n",
      "                                  'num_trainable_parameters': 389895.0},\n",
      "              'default_policy': {'curr_entropy_coeff': 0.0,\n",
      "                                 'curr_kl_coeff': 0.30000001192092896,\n",
      "                                 'default_optimizer_learning_rate': 5e-05,\n",
      "                                 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0),\n",
      "                                 'entropy': np.float32(1.7496248),\n",
      "                                 'gradients_default_optimizer_global_norm': np.float32(0.28407797),\n",
      "                                 'mean_kl_loss': np.float32(0.020344907),\n",
      "                                 'module_train_batch_size_mean': 128.0,\n",
      "                                 'num_module_steps_trained': 120704,\n",
      "                                 'num_module_steps_trained_lifetime': 241408,\n",
      "                                 'num_trainable_parameters': 389895.0,\n",
      "                                 'policy_loss': np.float32(-0.11305481),\n",
      "                                 'total_loss': np.float32(9.661371),\n",
      "                                 'vf_explained_var': np.float32(0.000749588),\n",
      "                                 'vf_loss': np.float32(9.770356),\n",
      "                                 'vf_loss_unclipped': np.float32(45138.707),\n",
      "                                 'weights_seq_no': 2.0}},\n",
      " 'node_ip': '192.168.0.18',\n",
      " 'num_env_steps_sampled_lifetime': 8000,\n",
      " 'num_env_steps_sampled_lifetime_throughput': 433.2683885169485,\n",
      " 'num_training_step_calls_per_iteration': 1,\n",
      " 'perf': {'cpu_util_percent': np.float64(47.46428571428572),\n",
      "          'ram_util_percent': np.float64(33.66428571428571)},\n",
      " 'pid': 199634,\n",
      " 'time_since_restore': 18.211180925369263,\n",
      " 'time_this_iter_s': 9.208211660385132,\n",
      " 'time_total_s': 18.211180925369263,\n",
      " 'timers': {'env_runner_sampling_timer': 2.030235829045123,\n",
      "            'learner_update_timer': 6.963489074587123,\n",
      "            'restore_env_runners': 1.984192436793819e-05,\n",
      "            'synch_env_connectors': 0.0018697060004342347,\n",
      "            'synch_weights': 0.002161212228529621,\n",
      "            'training_iteration': 8.998170644697966,\n",
      "            'training_step': 8.997936217312526},\n",
      " 'timestamp': 1749361153,\n",
      " 'training_iteration': 2,\n",
      " 'trial_id': 'default'}\n",
      "{'config': {'_disable_action_flattening': False,\n",
      "            '_disable_execution_plan_api': -1,\n",
      "            '_disable_initialize_loss_from_dummy_batch': False,\n",
      "            '_disable_preprocessor_api': False,\n",
      "            '_dont_auto_sync_env_runner_states': False,\n",
      "            '_enable_rl_module_api': -1,\n",
      "            '_env_to_module_connector': <function <lambda> at 0x7302b0391d00>,\n",
      "            '_fake_gpus': False,\n",
      "            '_is_atari': None,\n",
      "            '_learner_class': None,\n",
      "            '_learner_connector': None,\n",
      "            '_model_config': {},\n",
      "            '_module_to_env_connector': None,\n",
      "            '_per_module_overrides': {},\n",
      "            '_prior_exploration_config': {'type': 'StochasticSampling'},\n",
      "            '_rl_module_spec': None,\n",
      "            '_tf_policy_handles_more_than_one_loss': False,\n",
      "            '_torch_grad_scaler_class': None,\n",
      "            '_torch_lr_scheduler_classes': None,\n",
      "            '_train_batch_size_per_learner': None,\n",
      "            '_use_msgpack_checkpoints': False,\n",
      "            '_validate_config': True,\n",
      "            'action_mask_key': 'action_mask',\n",
      "            'action_space': None,\n",
      "            'actions_in_input_normalized': False,\n",
      "            'add_default_connectors_to_env_to_module_pipeline': True,\n",
      "            'add_default_connectors_to_learner_pipeline': True,\n",
      "            'add_default_connectors_to_module_to_env_pipeline': True,\n",
      "            'algorithm_config_overrides_per_module': {},\n",
      "            'always_attach_evaluation_results': -1,\n",
      "            'auto_wrap_old_gym_envs': -1,\n",
      "            'batch_mode': 'truncate_episodes',\n",
      "            'broadcast_env_runner_states': True,\n",
      "            'broadcast_offline_eval_runner_states': False,\n",
      "            'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>,\n",
      "            'callbacks_on_algorithm_init': None,\n",
      "            'callbacks_on_checkpoint_loaded': None,\n",
      "            'callbacks_on_env_runners_recreated': None,\n",
      "            'callbacks_on_environment_created': None,\n",
      "            'callbacks_on_episode_created': None,\n",
      "            'callbacks_on_episode_end': None,\n",
      "            'callbacks_on_episode_start': None,\n",
      "            'callbacks_on_episode_step': None,\n",
      "            'callbacks_on_evaluate_end': None,\n",
      "            'callbacks_on_evaluate_offline_end': None,\n",
      "            'callbacks_on_evaluate_offline_start': None,\n",
      "            'callbacks_on_evaluate_start': None,\n",
      "            'callbacks_on_offline_eval_runners_recreated': None,\n",
      "            'callbacks_on_sample_end': None,\n",
      "            'callbacks_on_train_result': None,\n",
      "            'checkpoint_trainable_policies_only': False,\n",
      "            'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>,\n",
      "            'clip_actions': False,\n",
      "            'clip_param': 0.3,\n",
      "            'clip_rewards': None,\n",
      "            'compress_observations': False,\n",
      "            'count_steps_by': 'env_steps',\n",
      "            'create_env_on_driver': False,\n",
      "            'create_local_env_runner': True,\n",
      "            'custom_async_evaluation_function': -1,\n",
      "            'custom_eval_function': None,\n",
      "            'custom_resources_per_env_runner': {},\n",
      "            'custom_resources_per_offline_eval_runner': {},\n",
      "            'dataset_num_iters_per_eval_runner': 1,\n",
      "            'dataset_num_iters_per_learner': None,\n",
      "            'delay_between_env_runner_restarts_s': 60.0,\n",
      "            'disable_env_checking': False,\n",
      "            'eager_max_retraces': 20,\n",
      "            'eager_tracing': True,\n",
      "            'enable_async_evaluation': -1,\n",
      "            'enable_connectors': -1,\n",
      "            'enable_env_runner_and_connector_v2': True,\n",
      "            'enable_rl_module_and_learner': True,\n",
      "            'enable_tf1_exec_eagerly': False,\n",
      "            'entropy_coeff': 0.0,\n",
      "            'entropy_coeff_schedule': None,\n",
      "            'env': 'Taxi-v3',\n",
      "            'env_config': {},\n",
      "            'env_runner_cls': None,\n",
      "            'env_runner_health_probe_timeout_s': 30.0,\n",
      "            'env_runner_restore_timeout_s': 1800.0,\n",
      "            'env_task_fn': -1,\n",
      "            'episode_lookback_horizon': 1,\n",
      "            'episodes_to_numpy': True,\n",
      "            'evaluation_auto_duration_max_env_steps_per_sample': 2000,\n",
      "            'evaluation_auto_duration_min_env_steps_per_sample': 100,\n",
      "            'evaluation_config': None,\n",
      "            'evaluation_duration': 10,\n",
      "            'evaluation_duration_unit': 'episodes',\n",
      "            'evaluation_force_reset_envs_before_iteration': True,\n",
      "            'evaluation_interval': None,\n",
      "            'evaluation_num_env_runners': 1,\n",
      "            'evaluation_parallel_to_training': False,\n",
      "            'evaluation_sample_timeout_s': 120.0,\n",
      "            'exploration_config': {},\n",
      "            'explore': True,\n",
      "            'export_native_model_files': False,\n",
      "            'extra_python_environs_for_driver': {},\n",
      "            'extra_python_environs_for_worker': {},\n",
      "            'fake_sampler': False,\n",
      "            'framework': 'torch',\n",
      "            'gamma': 0.99,\n",
      "            'grad_clip': None,\n",
      "            'grad_clip_by': 'global_norm',\n",
      "            'gym_env_vectorize_mode': 'SYNC',\n",
      "            'ignore_env_runner_failures': False,\n",
      "            'ignore_final_observation': False,\n",
      "            'ignore_offline_eval_runner_failures': False,\n",
      "            'in_evaluation': False,\n",
      "            'input': 'sampler',\n",
      "            'input_compress_columns': ['obs', 'new_obs'],\n",
      "            'input_config': {},\n",
      "            'input_filesystem': None,\n",
      "            'input_filesystem_kwargs': {},\n",
      "            'input_read_batch_size': None,\n",
      "            'input_read_episodes': False,\n",
      "            'input_read_method': 'read_parquet',\n",
      "            'input_read_method_kwargs': {},\n",
      "            'input_read_sample_batches': False,\n",
      "            'input_read_schema': {},\n",
      "            'input_spaces_jsonable': True,\n",
      "            'iter_batches_kwargs': {},\n",
      "            'keep_per_episode_custom_metrics': False,\n",
      "            'kl_coeff': 0.2,\n",
      "            'kl_target': 0.01,\n",
      "            'lambda': 1.0,\n",
      "            'learner_config_dict': {},\n",
      "            'local_gpu_idx': 0,\n",
      "            'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
      "                                      'intra_op_parallelism_threads': 8},\n",
      "            'log_gradients': True,\n",
      "            'log_level': 'WARN',\n",
      "            'log_sys_usage': True,\n",
      "            'logger_config': None,\n",
      "            'logger_creator': None,\n",
      "            'lr': 5e-05,\n",
      "            'lr_schedule': None,\n",
      "            'map_batches_kwargs': {},\n",
      "            'materialize_data': False,\n",
      "            'materialize_mapped_data': True,\n",
      "            'max_num_env_runner_restarts': 1000,\n",
      "            'max_num_offline_eval_runner_restarts': 1000,\n",
      "            'max_requests_in_flight_per_aggregator_actor': 3,\n",
      "            'max_requests_in_flight_per_env_runner': 1,\n",
      "            'max_requests_in_flight_per_learner': 3,\n",
      "            'max_requests_in_flight_per_offline_eval_runner': 1,\n",
      "            'merge_env_runner_states': 'training_only',\n",
      "            'metrics_episode_collection_timeout_s': 60.0,\n",
      "            'metrics_num_episodes_for_smoothing': 100,\n",
      "            'min_sample_timesteps_per_iteration': 0,\n",
      "            'min_time_s_per_iteration': None,\n",
      "            'min_train_timesteps_per_iteration': 0,\n",
      "            'minibatch_size': 128,\n",
      "            'model': {'_disable_action_flattening': False,\n",
      "                      '_disable_preprocessor_api': False,\n",
      "                      '_time_major': False,\n",
      "                      '_use_default_native_models': -1,\n",
      "                      'always_check_shapes': False,\n",
      "                      'attention_dim': 64,\n",
      "                      'attention_head_dim': 32,\n",
      "                      'attention_init_gru_gate_bias': 2.0,\n",
      "                      'attention_memory_inference': 50,\n",
      "                      'attention_memory_training': 50,\n",
      "                      'attention_num_heads': 1,\n",
      "                      'attention_num_transformer_units': 1,\n",
      "                      'attention_position_wise_mlp_dim': 32,\n",
      "                      'attention_use_n_prev_actions': 0,\n",
      "                      'attention_use_n_prev_rewards': 0,\n",
      "                      'conv_activation': 'relu',\n",
      "                      'conv_bias_initializer': None,\n",
      "                      'conv_bias_initializer_config': None,\n",
      "                      'conv_filters': None,\n",
      "                      'conv_kernel_initializer': None,\n",
      "                      'conv_kernel_initializer_config': None,\n",
      "                      'conv_transpose_bias_initializer': None,\n",
      "                      'conv_transpose_bias_initializer_config': None,\n",
      "                      'conv_transpose_kernel_initializer': None,\n",
      "                      'conv_transpose_kernel_initializer_config': None,\n",
      "                      'custom_action_dist': None,\n",
      "                      'custom_model': None,\n",
      "                      'custom_model_config': {},\n",
      "                      'custom_preprocessor': None,\n",
      "                      'dim': 84,\n",
      "                      'encoder_latent_dim': None,\n",
      "                      'fcnet_activation': 'tanh',\n",
      "                      'fcnet_bias_initializer': None,\n",
      "                      'fcnet_bias_initializer_config': None,\n",
      "                      'fcnet_hiddens': [256, 256],\n",
      "                      'fcnet_weights_initializer': None,\n",
      "                      'fcnet_weights_initializer_config': None,\n",
      "                      'framestack': True,\n",
      "                      'free_log_std': False,\n",
      "                      'grayscale': False,\n",
      "                      'log_std_clip_param': 20.0,\n",
      "                      'lstm_bias_initializer': None,\n",
      "                      'lstm_bias_initializer_config': None,\n",
      "                      'lstm_cell_size': 256,\n",
      "                      'lstm_use_prev_action': False,\n",
      "                      'lstm_use_prev_action_reward': -1,\n",
      "                      'lstm_use_prev_reward': False,\n",
      "                      'lstm_weights_initializer': None,\n",
      "                      'lstm_weights_initializer_config': None,\n",
      "                      'max_seq_len': 20,\n",
      "                      'no_final_linear': False,\n",
      "                      'post_fcnet_activation': 'relu',\n",
      "                      'post_fcnet_bias_initializer': None,\n",
      "                      'post_fcnet_bias_initializer_config': None,\n",
      "                      'post_fcnet_hiddens': [],\n",
      "                      'post_fcnet_weights_initializer': None,\n",
      "                      'post_fcnet_weights_initializer_config': None,\n",
      "                      'use_attention': False,\n",
      "                      'use_lstm': False,\n",
      "                      'vf_share_layers': False,\n",
      "                      'zero_mean': True},\n",
      "            'normalize_actions': True,\n",
      "            'num_aggregator_actors_per_learner': 0,\n",
      "            'num_consecutive_env_runner_failures_tolerance': 100,\n",
      "            'num_cpus_for_main_process': 1,\n",
      "            'num_cpus_per_env_runner': 1,\n",
      "            'num_cpus_per_learner': 'auto',\n",
      "            'num_cpus_per_offline_eval_runner': 1,\n",
      "            'num_env_runners': 2,\n",
      "            'num_envs_per_env_runner': 1,\n",
      "            'num_epochs': 30,\n",
      "            'num_gpus': 0,\n",
      "            'num_gpus_per_env_runner': 0,\n",
      "            'num_gpus_per_learner': 0,\n",
      "            'num_gpus_per_offline_eval_runner': 0,\n",
      "            'num_learners': 0,\n",
      "            'num_offline_eval_runners': 0,\n",
      "            'observation_filter': 'NoFilter',\n",
      "            'observation_fn': None,\n",
      "            'observation_space': None,\n",
      "            'off_policy_estimation_methods': {},\n",
      "            'offline_data_class': None,\n",
      "            'offline_eval_batch_size_per_runner': 256,\n",
      "            'offline_eval_rl_module_inference_only': False,\n",
      "            'offline_eval_runner_health_probe_timeout_s': 30.0,\n",
      "            'offline_eval_runner_restore_timeout_s': 1800.0,\n",
      "            'offline_evaluation_duration': 1,\n",
      "            'offline_evaluation_interval': None,\n",
      "            'offline_evaluation_parallel_to_training': False,\n",
      "            'offline_evaluation_timeout_s': 120.0,\n",
      "            'offline_loss_for_module_fn': None,\n",
      "            'offline_sampling': False,\n",
      "            'ope_split_batch_by_episode': True,\n",
      "            'optimizer': {},\n",
      "            'output': None,\n",
      "            'output_compress_columns': ['obs', 'new_obs'],\n",
      "            'output_config': {},\n",
      "            'output_filesystem': None,\n",
      "            'output_filesystem_kwargs': {},\n",
      "            'output_max_file_size': 67108864,\n",
      "            'output_max_rows_per_file': None,\n",
      "            'output_write_episodes': True,\n",
      "            'output_write_method': 'write_parquet',\n",
      "            'output_write_method_kwargs': {},\n",
      "            'output_write_remaining_data': False,\n",
      "            'placement_strategy': 'PACK',\n",
      "            'policies': {'default_policy': (None, None, None, None)},\n",
      "            'policies_to_train': None,\n",
      "            'policy_map_cache': -1,\n",
      "            'policy_map_capacity': 100,\n",
      "            'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x730510b16840>,\n",
      "            'policy_states_are_swappable': False,\n",
      "            'postprocess_inputs': False,\n",
      "            'prelearner_buffer_class': None,\n",
      "            'prelearner_buffer_kwargs': {},\n",
      "            'prelearner_class': None,\n",
      "            'prelearner_module_synch_period': 10,\n",
      "            'preprocessor_pref': 'deepmind',\n",
      "            'remote_env_batch_wait_ms': 0,\n",
      "            'remote_worker_envs': False,\n",
      "            'render_env': False,\n",
      "            'replay_sequence_length': None,\n",
      "            'restart_failed_env_runners': True,\n",
      "            'restart_failed_offline_eval_runners': True,\n",
      "            'restart_failed_sub_environments': False,\n",
      "            'rollout_fragment_length': 'auto',\n",
      "            'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
      "            'sample_timeout_s': 60.0,\n",
      "            'sampler_perf_stats_ema_coef': None,\n",
      "            'seed': None,\n",
      "            'sgd_minibatch_size': -1,\n",
      "            'shuffle_batch_per_epoch': True,\n",
      "            'shuffle_buffer_size': 0,\n",
      "            'simple_optimizer': False,\n",
      "            'sync_filters_on_rollout_workers_timeout_s': 10.0,\n",
      "            'synchronize_filters': -1,\n",
      "            'tf_session_args': {'allow_soft_placement': True,\n",
      "                                'device_count': {'CPU': 1},\n",
      "                                'gpu_options': {'allow_growth': True},\n",
      "                                'inter_op_parallelism_threads': 2,\n",
      "                                'intra_op_parallelism_threads': 2,\n",
      "                                'log_device_placement': False},\n",
      "            'torch_compile_learner': False,\n",
      "            'torch_compile_learner_dynamo_backend': 'inductor',\n",
      "            'torch_compile_learner_dynamo_mode': None,\n",
      "            'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>,\n",
      "            'torch_compile_worker': False,\n",
      "            'torch_compile_worker_dynamo_backend': 'onnxrt',\n",
      "            'torch_compile_worker_dynamo_mode': None,\n",
      "            'torch_ddp_kwargs': {},\n",
      "            'torch_skip_nan_gradients': False,\n",
      "            'train_batch_size': 4000,\n",
      "            'update_worker_filter_stats': True,\n",
      "            'use_critic': True,\n",
      "            'use_gae': True,\n",
      "            'use_kl_loss': True,\n",
      "            'use_worker_filter_stats': True,\n",
      "            'validate_env_runners_after_construction': True,\n",
      "            'validate_offline_eval_runners_after_construction': True,\n",
      "            'vf_clip_param': 10.0,\n",
      "            'vf_loss_coeff': 1.0,\n",
      "            'vf_share_layers': -1,\n",
      "            'worker_cls': -1},\n",
      " 'date': '2025-06-08_01-39-23',\n",
      " 'done': False,\n",
      " 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0},\n",
      " 'env_runners': {'agent_episode_returns_mean': {'default_agent': -681.12},\n",
      "                 'env_reset_timer': np.float64(0.00033987000642810017),\n",
      "                 'env_step_timer': np.float64(7.512349255303234e-05),\n",
      "                 'env_to_module_connector': {'connector_pipeline_timer': np.float64(0.0001788708419786436),\n",
      "                                             'timers': {'connectors': {'add_observations_from_episodes_to_batch': np.float64(7.570755210848891e-06),\n",
      "                                                                       'add_states_from_episodes_to_batch': np.float64(4.289958416193877e-06),\n",
      "                                                                       'add_time_dim_to_batch_and_zero_pad': np.float64(7.177709916740236e-06),\n",
      "                                                                       'batch_individual_items': np.float64(2.0702388055744455e-05),\n",
      "                                                                       'flatten_observations': np.float64(4.7106489158597e-05),\n",
      "                                                                       'numpy_to_tensor': np.float64(3.560939098444175e-05)}}},\n",
      "                 'env_to_module_sum_episodes_length_in': np.float64(131.04278635321435),\n",
      "                 'env_to_module_sum_episodes_length_out': np.float64(131.04278635321435),\n",
      "                 'episode_duration_sec_mean': 0.17662116684368812,\n",
      "                 'episode_len_max': 200,\n",
      "                 'episode_len_mean': 194.52,\n",
      "                 'episode_len_min': 36,\n",
      "                 'episode_return_max': -105.0,\n",
      "                 'episode_return_mean': -681.12,\n",
      "                 'episode_return_min': -821.0,\n",
      "                 'module_episode_returns_mean': {'default_policy': -681.12},\n",
      "                 'module_to_env_connector': {'connector_pipeline_timer': np.float64(0.0003857352997823706),\n",
      "                                             'timers': {'connectors': {'get_actions': np.float64(0.00018545200135212256),\n",
      "                                                                       'listify_data_for_vector_env': np.float64(3.455640530916691e-05),\n",
      "                                                                       'normalize_and_clip_actions': np.float64(2.9363680973175293e-05),\n",
      "                                                                       'remove_single_ts_time_rank_from_batch': np.float64(1.9433365768504823e-06),\n",
      "                                                                       'tensor_to_numpy': np.float64(5.253411349691217e-05),\n",
      "                                                                       'un_batch_to_individual_items': np.float64(1.693391369060972e-05)}}},\n",
      "                 'num_agent_steps_sampled': {'default_agent': 4000},\n",
      "                 'num_agent_steps_sampled_lifetime': {'default_agent': 12000},\n",
      "                 'num_env_steps_sampled': 4000,\n",
      "                 'num_env_steps_sampled_lifetime': 12000,\n",
      "                 'num_env_steps_sampled_lifetime_throughput': 414.38218768087074,\n",
      "                 'num_episodes': 21,\n",
      "                 'num_episodes_lifetime': 61,\n",
      "                 'num_module_steps_sampled': {'default_policy': 4000},\n",
      "                 'num_module_steps_sampled_lifetime': {'default_policy': 12000},\n",
      "                 'rlmodule_inference_timer': np.float64(0.0001435746217849751),\n",
      "                 'sample': np.float64(1.8589866923659892),\n",
      "                 'time_between_sampling': np.float64(7.1679890475637675),\n",
      "                 'weights_seq_no': 2.0},\n",
      " 'fault_tolerance': {'num_healthy_workers': 2, 'num_remote_worker_restarts': 0},\n",
      " 'hostname': 'brandon-ho-OMEN-by-HP-Laptop-15-dc0xxx',\n",
      " 'iterations_since_restore': 3,\n",
      " 'learners': {'__all_modules__': {'learner_connector': {'connector_pipeline_timer': 0.16966812008191487,\n",
      "                                                        'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.06780160041109669,\n",
      "                                                                                  'add_observations_from_episodes_to_batch': 0.0002909976590631413,\n",
      "                                                                                  'add_one_ts_to_episodes_and_truncate': 0.008627399673619425,\n",
      "                                                                                  'add_states_from_episodes_to_batch': 7.535884269804227e-06,\n",
      "                                                                                  'add_time_dim_to_batch_and_zero_pad': 2.28080797251896e-05,\n",
      "                                                                                  'batch_individual_items': 0.050030951669798984,\n",
      "                                                                                  'general_advantage_estimation': 0.042423665204540884,\n",
      "                                                                                  'numpy_to_tensor': 0.00015548793609853603}}},\n",
      "                                  'learner_connector_sum_episodes_length_in': 4000.0,\n",
      "                                  'learner_connector_sum_episodes_length_out': 4020.000398,\n",
      "                                  'num_env_steps_trained': 3792746,\n",
      "                                  'num_env_steps_trained_lifetime': 11375409,\n",
      "                                  'num_env_steps_trained_lifetime_throughput': 0.0,\n",
      "                                  'num_module_steps_trained': 120704,\n",
      "                                  'num_module_steps_trained_lifetime': 362112,\n",
      "                                  'num_non_trainable_parameters': 0.0,\n",
      "                                  'num_trainable_parameters': 389895.0},\n",
      "              'default_policy': {'curr_entropy_coeff': 0.0,\n",
      "                                 'curr_kl_coeff': 0.45000001788139343,\n",
      "                                 'default_optimizer_learning_rate': 5e-05,\n",
      "                                 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0),\n",
      "                                 'entropy': np.float32(1.7195888),\n",
      "                                 'gradients_default_optimizer_global_norm': np.float32(0.34896),\n",
      "                                 'mean_kl_loss': np.float32(0.025822971),\n",
      "                                 'module_train_batch_size_mean': 128.0,\n",
      "                                 'num_module_steps_trained': 120704,\n",
      "                                 'num_module_steps_trained_lifetime': 362112,\n",
      "                                 'num_trainable_parameters': 389895.0,\n",
      "                                 'policy_loss': np.float32(-0.06101933),\n",
      "                                 'total_loss': np.float32(9.946729),\n",
      "                                 'vf_explained_var': np.float32(6.0617924e-05),\n",
      "                                 'vf_loss': np.float32(10.0),\n",
      "                                 'vf_loss_unclipped': np.float32(44400.293),\n",
      "                                 'weights_seq_no': 3.0}},\n",
      " 'node_ip': '192.168.0.18',\n",
      " 'num_env_steps_sampled_lifetime': 12000,\n",
      " 'num_env_steps_sampled_lifetime_throughput': 414.38218768087074,\n",
      " 'num_training_step_calls_per_iteration': 1,\n",
      " 'perf': {'cpu_util_percent': np.float64(49.207692307692305),\n",
      "          'ram_util_percent': np.float64(33.669230769230765)},\n",
      " 'pid': 199634,\n",
      " 'time_since_restore': 27.83981728553772,\n",
      " 'time_this_iter_s': 9.628636360168457,\n",
      " 'time_total_s': 27.83981728553772,\n",
      " 'timers': {'env_runner_sampling_timer': 2.0288103646545412,\n",
      "            'learner_update_timer': 6.971134126721229,\n",
      "            'restore_env_runners': 1.9823725064634346e-05,\n",
      "            'synch_env_connectors': 0.0018690325104398651,\n",
      "            'synch_weights': 0.002159994886102504,\n",
      "            'training_iteration': 9.00439868993084,\n",
      "            'training_step': 9.00416363117931},\n",
      " 'timestamp': 1749361163,\n",
      " 'training_iteration': 3,\n",
      " 'trial_id': 'default'}\n",
      "{'config': {'_disable_action_flattening': False,\n",
      "            '_disable_execution_plan_api': -1,\n",
      "            '_disable_initialize_loss_from_dummy_batch': False,\n",
      "            '_disable_preprocessor_api': False,\n",
      "            '_dont_auto_sync_env_runner_states': False,\n",
      "            '_enable_rl_module_api': -1,\n",
      "            '_env_to_module_connector': <function <lambda> at 0x7302b0391d00>,\n",
      "            '_fake_gpus': False,\n",
      "            '_is_atari': None,\n",
      "            '_learner_class': None,\n",
      "            '_learner_connector': None,\n",
      "            '_model_config': {},\n",
      "            '_module_to_env_connector': None,\n",
      "            '_per_module_overrides': {},\n",
      "            '_prior_exploration_config': {'type': 'StochasticSampling'},\n",
      "            '_rl_module_spec': None,\n",
      "            '_tf_policy_handles_more_than_one_loss': False,\n",
      "            '_torch_grad_scaler_class': None,\n",
      "            '_torch_lr_scheduler_classes': None,\n",
      "            '_train_batch_size_per_learner': None,\n",
      "            '_use_msgpack_checkpoints': False,\n",
      "            '_validate_config': True,\n",
      "            'action_mask_key': 'action_mask',\n",
      "            'action_space': None,\n",
      "            'actions_in_input_normalized': False,\n",
      "            'add_default_connectors_to_env_to_module_pipeline': True,\n",
      "            'add_default_connectors_to_learner_pipeline': True,\n",
      "            'add_default_connectors_to_module_to_env_pipeline': True,\n",
      "            'algorithm_config_overrides_per_module': {},\n",
      "            'always_attach_evaluation_results': -1,\n",
      "            'auto_wrap_old_gym_envs': -1,\n",
      "            'batch_mode': 'truncate_episodes',\n",
      "            'broadcast_env_runner_states': True,\n",
      "            'broadcast_offline_eval_runner_states': False,\n",
      "            'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>,\n",
      "            'callbacks_on_algorithm_init': None,\n",
      "            'callbacks_on_checkpoint_loaded': None,\n",
      "            'callbacks_on_env_runners_recreated': None,\n",
      "            'callbacks_on_environment_created': None,\n",
      "            'callbacks_on_episode_created': None,\n",
      "            'callbacks_on_episode_end': None,\n",
      "            'callbacks_on_episode_start': None,\n",
      "            'callbacks_on_episode_step': None,\n",
      "            'callbacks_on_evaluate_end': None,\n",
      "            'callbacks_on_evaluate_offline_end': None,\n",
      "            'callbacks_on_evaluate_offline_start': None,\n",
      "            'callbacks_on_evaluate_start': None,\n",
      "            'callbacks_on_offline_eval_runners_recreated': None,\n",
      "            'callbacks_on_sample_end': None,\n",
      "            'callbacks_on_train_result': None,\n",
      "            'checkpoint_trainable_policies_only': False,\n",
      "            'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>,\n",
      "            'clip_actions': False,\n",
      "            'clip_param': 0.3,\n",
      "            'clip_rewards': None,\n",
      "            'compress_observations': False,\n",
      "            'count_steps_by': 'env_steps',\n",
      "            'create_env_on_driver': False,\n",
      "            'create_local_env_runner': True,\n",
      "            'custom_async_evaluation_function': -1,\n",
      "            'custom_eval_function': None,\n",
      "            'custom_resources_per_env_runner': {},\n",
      "            'custom_resources_per_offline_eval_runner': {},\n",
      "            'dataset_num_iters_per_eval_runner': 1,\n",
      "            'dataset_num_iters_per_learner': None,\n",
      "            'delay_between_env_runner_restarts_s': 60.0,\n",
      "            'disable_env_checking': False,\n",
      "            'eager_max_retraces': 20,\n",
      "            'eager_tracing': True,\n",
      "            'enable_async_evaluation': -1,\n",
      "            'enable_connectors': -1,\n",
      "            'enable_env_runner_and_connector_v2': True,\n",
      "            'enable_rl_module_and_learner': True,\n",
      "            'enable_tf1_exec_eagerly': False,\n",
      "            'entropy_coeff': 0.0,\n",
      "            'entropy_coeff_schedule': None,\n",
      "            'env': 'Taxi-v3',\n",
      "            'env_config': {},\n",
      "            'env_runner_cls': None,\n",
      "            'env_runner_health_probe_timeout_s': 30.0,\n",
      "            'env_runner_restore_timeout_s': 1800.0,\n",
      "            'env_task_fn': -1,\n",
      "            'episode_lookback_horizon': 1,\n",
      "            'episodes_to_numpy': True,\n",
      "            'evaluation_auto_duration_max_env_steps_per_sample': 2000,\n",
      "            'evaluation_auto_duration_min_env_steps_per_sample': 100,\n",
      "            'evaluation_config': None,\n",
      "            'evaluation_duration': 10,\n",
      "            'evaluation_duration_unit': 'episodes',\n",
      "            'evaluation_force_reset_envs_before_iteration': True,\n",
      "            'evaluation_interval': None,\n",
      "            'evaluation_num_env_runners': 1,\n",
      "            'evaluation_parallel_to_training': False,\n",
      "            'evaluation_sample_timeout_s': 120.0,\n",
      "            'exploration_config': {},\n",
      "            'explore': True,\n",
      "            'export_native_model_files': False,\n",
      "            'extra_python_environs_for_driver': {},\n",
      "            'extra_python_environs_for_worker': {},\n",
      "            'fake_sampler': False,\n",
      "            'framework': 'torch',\n",
      "            'gamma': 0.99,\n",
      "            'grad_clip': None,\n",
      "            'grad_clip_by': 'global_norm',\n",
      "            'gym_env_vectorize_mode': 'SYNC',\n",
      "            'ignore_env_runner_failures': False,\n",
      "            'ignore_final_observation': False,\n",
      "            'ignore_offline_eval_runner_failures': False,\n",
      "            'in_evaluation': False,\n",
      "            'input': 'sampler',\n",
      "            'input_compress_columns': ['obs', 'new_obs'],\n",
      "            'input_config': {},\n",
      "            'input_filesystem': None,\n",
      "            'input_filesystem_kwargs': {},\n",
      "            'input_read_batch_size': None,\n",
      "            'input_read_episodes': False,\n",
      "            'input_read_method': 'read_parquet',\n",
      "            'input_read_method_kwargs': {},\n",
      "            'input_read_sample_batches': False,\n",
      "            'input_read_schema': {},\n",
      "            'input_spaces_jsonable': True,\n",
      "            'iter_batches_kwargs': {},\n",
      "            'keep_per_episode_custom_metrics': False,\n",
      "            'kl_coeff': 0.2,\n",
      "            'kl_target': 0.01,\n",
      "            'lambda': 1.0,\n",
      "            'learner_config_dict': {},\n",
      "            'local_gpu_idx': 0,\n",
      "            'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
      "                                      'intra_op_parallelism_threads': 8},\n",
      "            'log_gradients': True,\n",
      "            'log_level': 'WARN',\n",
      "            'log_sys_usage': True,\n",
      "            'logger_config': None,\n",
      "            'logger_creator': None,\n",
      "            'lr': 5e-05,\n",
      "            'lr_schedule': None,\n",
      "            'map_batches_kwargs': {},\n",
      "            'materialize_data': False,\n",
      "            'materialize_mapped_data': True,\n",
      "            'max_num_env_runner_restarts': 1000,\n",
      "            'max_num_offline_eval_runner_restarts': 1000,\n",
      "            'max_requests_in_flight_per_aggregator_actor': 3,\n",
      "            'max_requests_in_flight_per_env_runner': 1,\n",
      "            'max_requests_in_flight_per_learner': 3,\n",
      "            'max_requests_in_flight_per_offline_eval_runner': 1,\n",
      "            'merge_env_runner_states': 'training_only',\n",
      "            'metrics_episode_collection_timeout_s': 60.0,\n",
      "            'metrics_num_episodes_for_smoothing': 100,\n",
      "            'min_sample_timesteps_per_iteration': 0,\n",
      "            'min_time_s_per_iteration': None,\n",
      "            'min_train_timesteps_per_iteration': 0,\n",
      "            'minibatch_size': 128,\n",
      "            'model': {'_disable_action_flattening': False,\n",
      "                      '_disable_preprocessor_api': False,\n",
      "                      '_time_major': False,\n",
      "                      '_use_default_native_models': -1,\n",
      "                      'always_check_shapes': False,\n",
      "                      'attention_dim': 64,\n",
      "                      'attention_head_dim': 32,\n",
      "                      'attention_init_gru_gate_bias': 2.0,\n",
      "                      'attention_memory_inference': 50,\n",
      "                      'attention_memory_training': 50,\n",
      "                      'attention_num_heads': 1,\n",
      "                      'attention_num_transformer_units': 1,\n",
      "                      'attention_position_wise_mlp_dim': 32,\n",
      "                      'attention_use_n_prev_actions': 0,\n",
      "                      'attention_use_n_prev_rewards': 0,\n",
      "                      'conv_activation': 'relu',\n",
      "                      'conv_bias_initializer': None,\n",
      "                      'conv_bias_initializer_config': None,\n",
      "                      'conv_filters': None,\n",
      "                      'conv_kernel_initializer': None,\n",
      "                      'conv_kernel_initializer_config': None,\n",
      "                      'conv_transpose_bias_initializer': None,\n",
      "                      'conv_transpose_bias_initializer_config': None,\n",
      "                      'conv_transpose_kernel_initializer': None,\n",
      "                      'conv_transpose_kernel_initializer_config': None,\n",
      "                      'custom_action_dist': None,\n",
      "                      'custom_model': None,\n",
      "                      'custom_model_config': {},\n",
      "                      'custom_preprocessor': None,\n",
      "                      'dim': 84,\n",
      "                      'encoder_latent_dim': None,\n",
      "                      'fcnet_activation': 'tanh',\n",
      "                      'fcnet_bias_initializer': None,\n",
      "                      'fcnet_bias_initializer_config': None,\n",
      "                      'fcnet_hiddens': [256, 256],\n",
      "                      'fcnet_weights_initializer': None,\n",
      "                      'fcnet_weights_initializer_config': None,\n",
      "                      'framestack': True,\n",
      "                      'free_log_std': False,\n",
      "                      'grayscale': False,\n",
      "                      'log_std_clip_param': 20.0,\n",
      "                      'lstm_bias_initializer': None,\n",
      "                      'lstm_bias_initializer_config': None,\n",
      "                      'lstm_cell_size': 256,\n",
      "                      'lstm_use_prev_action': False,\n",
      "                      'lstm_use_prev_action_reward': -1,\n",
      "                      'lstm_use_prev_reward': False,\n",
      "                      'lstm_weights_initializer': None,\n",
      "                      'lstm_weights_initializer_config': None,\n",
      "                      'max_seq_len': 20,\n",
      "                      'no_final_linear': False,\n",
      "                      'post_fcnet_activation': 'relu',\n",
      "                      'post_fcnet_bias_initializer': None,\n",
      "                      'post_fcnet_bias_initializer_config': None,\n",
      "                      'post_fcnet_hiddens': [],\n",
      "                      'post_fcnet_weights_initializer': None,\n",
      "                      'post_fcnet_weights_initializer_config': None,\n",
      "                      'use_attention': False,\n",
      "                      'use_lstm': False,\n",
      "                      'vf_share_layers': False,\n",
      "                      'zero_mean': True},\n",
      "            'normalize_actions': True,\n",
      "            'num_aggregator_actors_per_learner': 0,\n",
      "            'num_consecutive_env_runner_failures_tolerance': 100,\n",
      "            'num_cpus_for_main_process': 1,\n",
      "            'num_cpus_per_env_runner': 1,\n",
      "            'num_cpus_per_learner': 'auto',\n",
      "            'num_cpus_per_offline_eval_runner': 1,\n",
      "            'num_env_runners': 2,\n",
      "            'num_envs_per_env_runner': 1,\n",
      "            'num_epochs': 30,\n",
      "            'num_gpus': 0,\n",
      "            'num_gpus_per_env_runner': 0,\n",
      "            'num_gpus_per_learner': 0,\n",
      "            'num_gpus_per_offline_eval_runner': 0,\n",
      "            'num_learners': 0,\n",
      "            'num_offline_eval_runners': 0,\n",
      "            'observation_filter': 'NoFilter',\n",
      "            'observation_fn': None,\n",
      "            'observation_space': None,\n",
      "            'off_policy_estimation_methods': {},\n",
      "            'offline_data_class': None,\n",
      "            'offline_eval_batch_size_per_runner': 256,\n",
      "            'offline_eval_rl_module_inference_only': False,\n",
      "            'offline_eval_runner_health_probe_timeout_s': 30.0,\n",
      "            'offline_eval_runner_restore_timeout_s': 1800.0,\n",
      "            'offline_evaluation_duration': 1,\n",
      "            'offline_evaluation_interval': None,\n",
      "            'offline_evaluation_parallel_to_training': False,\n",
      "            'offline_evaluation_timeout_s': 120.0,\n",
      "            'offline_loss_for_module_fn': None,\n",
      "            'offline_sampling': False,\n",
      "            'ope_split_batch_by_episode': True,\n",
      "            'optimizer': {},\n",
      "            'output': None,\n",
      "            'output_compress_columns': ['obs', 'new_obs'],\n",
      "            'output_config': {},\n",
      "            'output_filesystem': None,\n",
      "            'output_filesystem_kwargs': {},\n",
      "            'output_max_file_size': 67108864,\n",
      "            'output_max_rows_per_file': None,\n",
      "            'output_write_episodes': True,\n",
      "            'output_write_method': 'write_parquet',\n",
      "            'output_write_method_kwargs': {},\n",
      "            'output_write_remaining_data': False,\n",
      "            'placement_strategy': 'PACK',\n",
      "            'policies': {'default_policy': (None, None, None, None)},\n",
      "            'policies_to_train': None,\n",
      "            'policy_map_cache': -1,\n",
      "            'policy_map_capacity': 100,\n",
      "            'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x730510b16840>,\n",
      "            'policy_states_are_swappable': False,\n",
      "            'postprocess_inputs': False,\n",
      "            'prelearner_buffer_class': None,\n",
      "            'prelearner_buffer_kwargs': {},\n",
      "            'prelearner_class': None,\n",
      "            'prelearner_module_synch_period': 10,\n",
      "            'preprocessor_pref': 'deepmind',\n",
      "            'remote_env_batch_wait_ms': 0,\n",
      "            'remote_worker_envs': False,\n",
      "            'render_env': False,\n",
      "            'replay_sequence_length': None,\n",
      "            'restart_failed_env_runners': True,\n",
      "            'restart_failed_offline_eval_runners': True,\n",
      "            'restart_failed_sub_environments': False,\n",
      "            'rollout_fragment_length': 'auto',\n",
      "            'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
      "            'sample_timeout_s': 60.0,\n",
      "            'sampler_perf_stats_ema_coef': None,\n",
      "            'seed': None,\n",
      "            'sgd_minibatch_size': -1,\n",
      "            'shuffle_batch_per_epoch': True,\n",
      "            'shuffle_buffer_size': 0,\n",
      "            'simple_optimizer': False,\n",
      "            'sync_filters_on_rollout_workers_timeout_s': 10.0,\n",
      "            'synchronize_filters': -1,\n",
      "            'tf_session_args': {'allow_soft_placement': True,\n",
      "                                'device_count': {'CPU': 1},\n",
      "                                'gpu_options': {'allow_growth': True},\n",
      "                                'inter_op_parallelism_threads': 2,\n",
      "                                'intra_op_parallelism_threads': 2,\n",
      "                                'log_device_placement': False},\n",
      "            'torch_compile_learner': False,\n",
      "            'torch_compile_learner_dynamo_backend': 'inductor',\n",
      "            'torch_compile_learner_dynamo_mode': None,\n",
      "            'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>,\n",
      "            'torch_compile_worker': False,\n",
      "            'torch_compile_worker_dynamo_backend': 'onnxrt',\n",
      "            'torch_compile_worker_dynamo_mode': None,\n",
      "            'torch_ddp_kwargs': {},\n",
      "            'torch_skip_nan_gradients': False,\n",
      "            'train_batch_size': 4000,\n",
      "            'update_worker_filter_stats': True,\n",
      "            'use_critic': True,\n",
      "            'use_gae': True,\n",
      "            'use_kl_loss': True,\n",
      "            'use_worker_filter_stats': True,\n",
      "            'validate_env_runners_after_construction': True,\n",
      "            'validate_offline_eval_runners_after_construction': True,\n",
      "            'vf_clip_param': 10.0,\n",
      "            'vf_loss_coeff': 1.0,\n",
      "            'vf_share_layers': -1,\n",
      "            'worker_cls': -1},\n",
      " 'date': '2025-06-08_01-39-33',\n",
      " 'done': False,\n",
      " 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0},\n",
      " 'env_runners': {'agent_episode_returns_mean': {'default_agent': -643.76},\n",
      "                 'env_reset_timer': np.float64(0.00033987000642810017),\n",
      "                 'env_step_timer': np.float64(7.534179471681659e-05),\n",
      "                 'env_to_module_connector': {'connector_pipeline_timer': np.float64(0.00017933936828038043),\n",
      "                                             'timers': {'connectors': {'add_observations_from_episodes_to_batch': np.float64(7.590075049801405e-06),\n",
      "                                                                       'add_states_from_episodes_to_batch': np.float64(4.299636268486648e-06),\n",
      "                                                                       'add_time_dim_to_batch_and_zero_pad': np.float64(7.19798840011438e-06),\n",
      "                                                                       'batch_individual_items': np.float64(2.0740101719186627e-05),\n",
      "                                                                       'flatten_observations': np.float64(4.723753526223113e-05),\n",
      "                                                                       'numpy_to_tensor': np.float64(3.572442883912761e-05)}}},\n",
      "                 'env_to_module_sum_episodes_length_in': np.float64(130.8094674241107),\n",
      "                 'env_to_module_sum_episodes_length_out': np.float64(130.8094674241107),\n",
      "                 'episode_duration_sec_mean': 0.18437775770493317,\n",
      "                 'episode_len_max': 200,\n",
      "                 'episode_len_mean': 194.84,\n",
      "                 'episode_len_min': 90,\n",
      "                 'episode_return_max': -258.0,\n",
      "                 'episode_return_mean': -643.76,\n",
      "                 'episode_return_min': -776.0,\n",
      "                 'module_episode_returns_mean': {'default_policy': -643.76},\n",
      "                 'module_to_env_connector': {'connector_pipeline_timer': np.float64(0.0003868943957714313),\n",
      "                                             'timers': {'connectors': {'get_actions': np.float64(0.00018607904108751178),\n",
      "                                                                       'listify_data_for_vector_env': np.float64(3.462974704084536e-05),\n",
      "                                                                       'normalize_and_clip_actions': np.float64(2.944233759434302e-05),\n",
      "                                                                       'remove_single_ts_time_rank_from_batch': np.float64(1.9486774208020825e-06),\n",
      "                                                                       'tensor_to_numpy': np.float64(5.267969955966775e-05),\n",
      "                                                                       'un_batch_to_individual_items': np.float64(1.698623231328119e-05)}}},\n",
      "                 'num_agent_steps_sampled': {'default_agent': 4000},\n",
      "                 'num_agent_steps_sampled_lifetime': {'default_agent': 16000},\n",
      "                 'num_env_steps_sampled': 4000,\n",
      "                 'num_env_steps_sampled_lifetime': 16000,\n",
      "                 'num_env_steps_sampled_lifetime_throughput': 408.6433468487383,\n",
      "                 'num_episodes': 21,\n",
      "                 'num_episodes_lifetime': 82,\n",
      "                 'num_module_steps_sampled': {'default_policy': 4000},\n",
      "                 'num_module_steps_sampled_lifetime': {'default_policy': 16000},\n",
      "                 'rlmodule_inference_timer': np.float64(0.000144106249974489),\n",
      "                 'sample': np.float64(1.859016674690871),\n",
      "                 'time_between_sampling': np.float64(7.168156387877054),\n",
      "                 'weights_seq_no': 3.0},\n",
      " 'fault_tolerance': {'num_healthy_workers': 2, 'num_remote_worker_restarts': 0},\n",
      " 'hostname': 'brandon-ho-OMEN-by-HP-Laptop-15-dc0xxx',\n",
      " 'iterations_since_restore': 4,\n",
      " 'learners': {'__all_modules__': {'learner_connector': {'connector_pipeline_timer': 0.16966805868205223,\n",
      "                                                        'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.06779961857593142,\n",
      "                                                                                  'add_observations_from_episodes_to_batch': 0.000290968055947592,\n",
      "                                                                                  'add_one_ts_to_episodes_and_truncate': 0.008626304847308931,\n",
      "                                                                                  'add_states_from_episodes_to_batch': 7.536925228873441e-06,\n",
      "                                                                                  'add_time_dim_to_batch_and_zero_pad': 2.2809876256578427e-05,\n",
      "                                                                                  'batch_individual_items': 0.05004225838753112,\n",
      "                                                                                  'general_advantage_estimation': 0.04241541991145486,\n",
      "                                                                                  'numpy_to_tensor': 0.00015549444165654453}}},\n",
      "                                  'learner_connector_sum_episodes_length_in': 4000.0,\n",
      "                                  'learner_connector_sum_episodes_length_out': 4020.00089003,\n",
      "                                  'num_env_steps_trained': 3792746,\n",
      "                                  'num_env_steps_trained_lifetime': 15168155,\n",
      "                                  'num_env_steps_trained_lifetime_throughput': 0.0,\n",
      "                                  'num_module_steps_trained': 120704,\n",
      "                                  'num_module_steps_trained_lifetime': 482816,\n",
      "                                  'num_non_trainable_parameters': 0.0,\n",
      "                                  'num_trainable_parameters': 389895.0},\n",
      "              'default_policy': {'curr_entropy_coeff': 0.0,\n",
      "                                 'curr_kl_coeff': 0.675000011920929,\n",
      "                                 'default_optimizer_learning_rate': 5e-05,\n",
      "                                 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0),\n",
      "                                 'entropy': np.float32(1.6910732),\n",
      "                                 'gradients_default_optimizer_global_norm': np.float32(0.56985074),\n",
      "                                 'mean_kl_loss': np.float32(0.02400462),\n",
      "                                 'module_train_batch_size_mean': 128.0,\n",
      "                                 'num_module_steps_trained': 120704,\n",
      "                                 'num_module_steps_trained_lifetime': 482816,\n",
      "                                 'num_trainable_parameters': 389895.0,\n",
      "                                 'policy_loss': np.float32(-0.32197112),\n",
      "                                 'total_loss': np.float32(9.58093),\n",
      "                                 'vf_explained_var': np.float32(0.0027454495),\n",
      "                                 'vf_loss': np.float32(9.892099),\n",
      "                                 'vf_loss_unclipped': np.float32(29929.387),\n",
      "                                 'weights_seq_no': 4.0}},\n",
      " 'node_ip': '192.168.0.18',\n",
      " 'num_env_steps_sampled_lifetime': 16000,\n",
      " 'num_env_steps_sampled_lifetime_throughput': 408.6433468487383,\n",
      " 'num_training_step_calls_per_iteration': 1,\n",
      " 'perf': {'cpu_util_percent': np.float64(46.84285714285715),\n",
      "          'ram_util_percent': np.float64(33.664285714285725)},\n",
      " 'pid': 199634,\n",
      " 'time_since_restore': 37.59848713874817,\n",
      " 'time_this_iter_s': 9.75866985321045,\n",
      " 'time_total_s': 37.59848713874817,\n",
      " 'timers': {'env_runner_sampling_timer': 2.0293439567880283,\n",
      "            'learner_update_timer': 6.978053406983783,\n",
      "            'restore_env_runners': 1.9720777829439612e-05,\n",
      "            'synch_env_connectors': 0.0018696354652463921,\n",
      "            'synch_weights': 0.0021591692371606187,\n",
      "            'training_iteration': 9.011860199051553,\n",
      "            'training_step': 9.011624461317613},\n",
      " 'timestamp': 1749361173,\n",
      " 'training_iteration': 4,\n",
      " 'trial_id': 'default'}\n",
      "{'config': {'_disable_action_flattening': False,\n",
      "            '_disable_execution_plan_api': -1,\n",
      "            '_disable_initialize_loss_from_dummy_batch': False,\n",
      "            '_disable_preprocessor_api': False,\n",
      "            '_dont_auto_sync_env_runner_states': False,\n",
      "            '_enable_rl_module_api': -1,\n",
      "            '_env_to_module_connector': <function <lambda> at 0x7302b0391d00>,\n",
      "            '_fake_gpus': False,\n",
      "            '_is_atari': None,\n",
      "            '_learner_class': None,\n",
      "            '_learner_connector': None,\n",
      "            '_model_config': {},\n",
      "            '_module_to_env_connector': None,\n",
      "            '_per_module_overrides': {},\n",
      "            '_prior_exploration_config': {'type': 'StochasticSampling'},\n",
      "            '_rl_module_spec': None,\n",
      "            '_tf_policy_handles_more_than_one_loss': False,\n",
      "            '_torch_grad_scaler_class': None,\n",
      "            '_torch_lr_scheduler_classes': None,\n",
      "            '_train_batch_size_per_learner': None,\n",
      "            '_use_msgpack_checkpoints': False,\n",
      "            '_validate_config': True,\n",
      "            'action_mask_key': 'action_mask',\n",
      "            'action_space': None,\n",
      "            'actions_in_input_normalized': False,\n",
      "            'add_default_connectors_to_env_to_module_pipeline': True,\n",
      "            'add_default_connectors_to_learner_pipeline': True,\n",
      "            'add_default_connectors_to_module_to_env_pipeline': True,\n",
      "            'algorithm_config_overrides_per_module': {},\n",
      "            'always_attach_evaluation_results': -1,\n",
      "            'auto_wrap_old_gym_envs': -1,\n",
      "            'batch_mode': 'truncate_episodes',\n",
      "            'broadcast_env_runner_states': True,\n",
      "            'broadcast_offline_eval_runner_states': False,\n",
      "            'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>,\n",
      "            'callbacks_on_algorithm_init': None,\n",
      "            'callbacks_on_checkpoint_loaded': None,\n",
      "            'callbacks_on_env_runners_recreated': None,\n",
      "            'callbacks_on_environment_created': None,\n",
      "            'callbacks_on_episode_created': None,\n",
      "            'callbacks_on_episode_end': None,\n",
      "            'callbacks_on_episode_start': None,\n",
      "            'callbacks_on_episode_step': None,\n",
      "            'callbacks_on_evaluate_end': None,\n",
      "            'callbacks_on_evaluate_offline_end': None,\n",
      "            'callbacks_on_evaluate_offline_start': None,\n",
      "            'callbacks_on_evaluate_start': None,\n",
      "            'callbacks_on_offline_eval_runners_recreated': None,\n",
      "            'callbacks_on_sample_end': None,\n",
      "            'callbacks_on_train_result': None,\n",
      "            'checkpoint_trainable_policies_only': False,\n",
      "            'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>,\n",
      "            'clip_actions': False,\n",
      "            'clip_param': 0.3,\n",
      "            'clip_rewards': None,\n",
      "            'compress_observations': False,\n",
      "            'count_steps_by': 'env_steps',\n",
      "            'create_env_on_driver': False,\n",
      "            'create_local_env_runner': True,\n",
      "            'custom_async_evaluation_function': -1,\n",
      "            'custom_eval_function': None,\n",
      "            'custom_resources_per_env_runner': {},\n",
      "            'custom_resources_per_offline_eval_runner': {},\n",
      "            'dataset_num_iters_per_eval_runner': 1,\n",
      "            'dataset_num_iters_per_learner': None,\n",
      "            'delay_between_env_runner_restarts_s': 60.0,\n",
      "            'disable_env_checking': False,\n",
      "            'eager_max_retraces': 20,\n",
      "            'eager_tracing': True,\n",
      "            'enable_async_evaluation': -1,\n",
      "            'enable_connectors': -1,\n",
      "            'enable_env_runner_and_connector_v2': True,\n",
      "            'enable_rl_module_and_learner': True,\n",
      "            'enable_tf1_exec_eagerly': False,\n",
      "            'entropy_coeff': 0.0,\n",
      "            'entropy_coeff_schedule': None,\n",
      "            'env': 'Taxi-v3',\n",
      "            'env_config': {},\n",
      "            'env_runner_cls': None,\n",
      "            'env_runner_health_probe_timeout_s': 30.0,\n",
      "            'env_runner_restore_timeout_s': 1800.0,\n",
      "            'env_task_fn': -1,\n",
      "            'episode_lookback_horizon': 1,\n",
      "            'episodes_to_numpy': True,\n",
      "            'evaluation_auto_duration_max_env_steps_per_sample': 2000,\n",
      "            'evaluation_auto_duration_min_env_steps_per_sample': 100,\n",
      "            'evaluation_config': None,\n",
      "            'evaluation_duration': 10,\n",
      "            'evaluation_duration_unit': 'episodes',\n",
      "            'evaluation_force_reset_envs_before_iteration': True,\n",
      "            'evaluation_interval': None,\n",
      "            'evaluation_num_env_runners': 1,\n",
      "            'evaluation_parallel_to_training': False,\n",
      "            'evaluation_sample_timeout_s': 120.0,\n",
      "            'exploration_config': {},\n",
      "            'explore': True,\n",
      "            'export_native_model_files': False,\n",
      "            'extra_python_environs_for_driver': {},\n",
      "            'extra_python_environs_for_worker': {},\n",
      "            'fake_sampler': False,\n",
      "            'framework': 'torch',\n",
      "            'gamma': 0.99,\n",
      "            'grad_clip': None,\n",
      "            'grad_clip_by': 'global_norm',\n",
      "            'gym_env_vectorize_mode': 'SYNC',\n",
      "            'ignore_env_runner_failures': False,\n",
      "            'ignore_final_observation': False,\n",
      "            'ignore_offline_eval_runner_failures': False,\n",
      "            'in_evaluation': False,\n",
      "            'input': 'sampler',\n",
      "            'input_compress_columns': ['obs', 'new_obs'],\n",
      "            'input_config': {},\n",
      "            'input_filesystem': None,\n",
      "            'input_filesystem_kwargs': {},\n",
      "            'input_read_batch_size': None,\n",
      "            'input_read_episodes': False,\n",
      "            'input_read_method': 'read_parquet',\n",
      "            'input_read_method_kwargs': {},\n",
      "            'input_read_sample_batches': False,\n",
      "            'input_read_schema': {},\n",
      "            'input_spaces_jsonable': True,\n",
      "            'iter_batches_kwargs': {},\n",
      "            'keep_per_episode_custom_metrics': False,\n",
      "            'kl_coeff': 0.2,\n",
      "            'kl_target': 0.01,\n",
      "            'lambda': 1.0,\n",
      "            'learner_config_dict': {},\n",
      "            'local_gpu_idx': 0,\n",
      "            'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
      "                                      'intra_op_parallelism_threads': 8},\n",
      "            'log_gradients': True,\n",
      "            'log_level': 'WARN',\n",
      "            'log_sys_usage': True,\n",
      "            'logger_config': None,\n",
      "            'logger_creator': None,\n",
      "            'lr': 5e-05,\n",
      "            'lr_schedule': None,\n",
      "            'map_batches_kwargs': {},\n",
      "            'materialize_data': False,\n",
      "            'materialize_mapped_data': True,\n",
      "            'max_num_env_runner_restarts': 1000,\n",
      "            'max_num_offline_eval_runner_restarts': 1000,\n",
      "            'max_requests_in_flight_per_aggregator_actor': 3,\n",
      "            'max_requests_in_flight_per_env_runner': 1,\n",
      "            'max_requests_in_flight_per_learner': 3,\n",
      "            'max_requests_in_flight_per_offline_eval_runner': 1,\n",
      "            'merge_env_runner_states': 'training_only',\n",
      "            'metrics_episode_collection_timeout_s': 60.0,\n",
      "            'metrics_num_episodes_for_smoothing': 100,\n",
      "            'min_sample_timesteps_per_iteration': 0,\n",
      "            'min_time_s_per_iteration': None,\n",
      "            'min_train_timesteps_per_iteration': 0,\n",
      "            'minibatch_size': 128,\n",
      "            'model': {'_disable_action_flattening': False,\n",
      "                      '_disable_preprocessor_api': False,\n",
      "                      '_time_major': False,\n",
      "                      '_use_default_native_models': -1,\n",
      "                      'always_check_shapes': False,\n",
      "                      'attention_dim': 64,\n",
      "                      'attention_head_dim': 32,\n",
      "                      'attention_init_gru_gate_bias': 2.0,\n",
      "                      'attention_memory_inference': 50,\n",
      "                      'attention_memory_training': 50,\n",
      "                      'attention_num_heads': 1,\n",
      "                      'attention_num_transformer_units': 1,\n",
      "                      'attention_position_wise_mlp_dim': 32,\n",
      "                      'attention_use_n_prev_actions': 0,\n",
      "                      'attention_use_n_prev_rewards': 0,\n",
      "                      'conv_activation': 'relu',\n",
      "                      'conv_bias_initializer': None,\n",
      "                      'conv_bias_initializer_config': None,\n",
      "                      'conv_filters': None,\n",
      "                      'conv_kernel_initializer': None,\n",
      "                      'conv_kernel_initializer_config': None,\n",
      "                      'conv_transpose_bias_initializer': None,\n",
      "                      'conv_transpose_bias_initializer_config': None,\n",
      "                      'conv_transpose_kernel_initializer': None,\n",
      "                      'conv_transpose_kernel_initializer_config': None,\n",
      "                      'custom_action_dist': None,\n",
      "                      'custom_model': None,\n",
      "                      'custom_model_config': {},\n",
      "                      'custom_preprocessor': None,\n",
      "                      'dim': 84,\n",
      "                      'encoder_latent_dim': None,\n",
      "                      'fcnet_activation': 'tanh',\n",
      "                      'fcnet_bias_initializer': None,\n",
      "                      'fcnet_bias_initializer_config': None,\n",
      "                      'fcnet_hiddens': [256, 256],\n",
      "                      'fcnet_weights_initializer': None,\n",
      "                      'fcnet_weights_initializer_config': None,\n",
      "                      'framestack': True,\n",
      "                      'free_log_std': False,\n",
      "                      'grayscale': False,\n",
      "                      'log_std_clip_param': 20.0,\n",
      "                      'lstm_bias_initializer': None,\n",
      "                      'lstm_bias_initializer_config': None,\n",
      "                      'lstm_cell_size': 256,\n",
      "                      'lstm_use_prev_action': False,\n",
      "                      'lstm_use_prev_action_reward': -1,\n",
      "                      'lstm_use_prev_reward': False,\n",
      "                      'lstm_weights_initializer': None,\n",
      "                      'lstm_weights_initializer_config': None,\n",
      "                      'max_seq_len': 20,\n",
      "                      'no_final_linear': False,\n",
      "                      'post_fcnet_activation': 'relu',\n",
      "                      'post_fcnet_bias_initializer': None,\n",
      "                      'post_fcnet_bias_initializer_config': None,\n",
      "                      'post_fcnet_hiddens': [],\n",
      "                      'post_fcnet_weights_initializer': None,\n",
      "                      'post_fcnet_weights_initializer_config': None,\n",
      "                      'use_attention': False,\n",
      "                      'use_lstm': False,\n",
      "                      'vf_share_layers': False,\n",
      "                      'zero_mean': True},\n",
      "            'normalize_actions': True,\n",
      "            'num_aggregator_actors_per_learner': 0,\n",
      "            'num_consecutive_env_runner_failures_tolerance': 100,\n",
      "            'num_cpus_for_main_process': 1,\n",
      "            'num_cpus_per_env_runner': 1,\n",
      "            'num_cpus_per_learner': 'auto',\n",
      "            'num_cpus_per_offline_eval_runner': 1,\n",
      "            'num_env_runners': 2,\n",
      "            'num_envs_per_env_runner': 1,\n",
      "            'num_epochs': 30,\n",
      "            'num_gpus': 0,\n",
      "            'num_gpus_per_env_runner': 0,\n",
      "            'num_gpus_per_learner': 0,\n",
      "            'num_gpus_per_offline_eval_runner': 0,\n",
      "            'num_learners': 0,\n",
      "            'num_offline_eval_runners': 0,\n",
      "            'observation_filter': 'NoFilter',\n",
      "            'observation_fn': None,\n",
      "            'observation_space': None,\n",
      "            'off_policy_estimation_methods': {},\n",
      "            'offline_data_class': None,\n",
      "            'offline_eval_batch_size_per_runner': 256,\n",
      "            'offline_eval_rl_module_inference_only': False,\n",
      "            'offline_eval_runner_health_probe_timeout_s': 30.0,\n",
      "            'offline_eval_runner_restore_timeout_s': 1800.0,\n",
      "            'offline_evaluation_duration': 1,\n",
      "            'offline_evaluation_interval': None,\n",
      "            'offline_evaluation_parallel_to_training': False,\n",
      "            'offline_evaluation_timeout_s': 120.0,\n",
      "            'offline_loss_for_module_fn': None,\n",
      "            'offline_sampling': False,\n",
      "            'ope_split_batch_by_episode': True,\n",
      "            'optimizer': {},\n",
      "            'output': None,\n",
      "            'output_compress_columns': ['obs', 'new_obs'],\n",
      "            'output_config': {},\n",
      "            'output_filesystem': None,\n",
      "            'output_filesystem_kwargs': {},\n",
      "            'output_max_file_size': 67108864,\n",
      "            'output_max_rows_per_file': None,\n",
      "            'output_write_episodes': True,\n",
      "            'output_write_method': 'write_parquet',\n",
      "            'output_write_method_kwargs': {},\n",
      "            'output_write_remaining_data': False,\n",
      "            'placement_strategy': 'PACK',\n",
      "            'policies': {'default_policy': (None, None, None, None)},\n",
      "            'policies_to_train': None,\n",
      "            'policy_map_cache': -1,\n",
      "            'policy_map_capacity': 100,\n",
      "            'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x730510b16840>,\n",
      "            'policy_states_are_swappable': False,\n",
      "            'postprocess_inputs': False,\n",
      "            'prelearner_buffer_class': None,\n",
      "            'prelearner_buffer_kwargs': {},\n",
      "            'prelearner_class': None,\n",
      "            'prelearner_module_synch_period': 10,\n",
      "            'preprocessor_pref': 'deepmind',\n",
      "            'remote_env_batch_wait_ms': 0,\n",
      "            'remote_worker_envs': False,\n",
      "            'render_env': False,\n",
      "            'replay_sequence_length': None,\n",
      "            'restart_failed_env_runners': True,\n",
      "            'restart_failed_offline_eval_runners': True,\n",
      "            'restart_failed_sub_environments': False,\n",
      "            'rollout_fragment_length': 'auto',\n",
      "            'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
      "            'sample_timeout_s': 60.0,\n",
      "            'sampler_perf_stats_ema_coef': None,\n",
      "            'seed': None,\n",
      "            'sgd_minibatch_size': -1,\n",
      "            'shuffle_batch_per_epoch': True,\n",
      "            'shuffle_buffer_size': 0,\n",
      "            'simple_optimizer': False,\n",
      "            'sync_filters_on_rollout_workers_timeout_s': 10.0,\n",
      "            'synchronize_filters': -1,\n",
      "            'tf_session_args': {'allow_soft_placement': True,\n",
      "                                'device_count': {'CPU': 1},\n",
      "                                'gpu_options': {'allow_growth': True},\n",
      "                                'inter_op_parallelism_threads': 2,\n",
      "                                'intra_op_parallelism_threads': 2,\n",
      "                                'log_device_placement': False},\n",
      "            'torch_compile_learner': False,\n",
      "            'torch_compile_learner_dynamo_backend': 'inductor',\n",
      "            'torch_compile_learner_dynamo_mode': None,\n",
      "            'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>,\n",
      "            'torch_compile_worker': False,\n",
      "            'torch_compile_worker_dynamo_backend': 'onnxrt',\n",
      "            'torch_compile_worker_dynamo_mode': None,\n",
      "            'torch_ddp_kwargs': {},\n",
      "            'torch_skip_nan_gradients': False,\n",
      "            'train_batch_size': 4000,\n",
      "            'update_worker_filter_stats': True,\n",
      "            'use_critic': True,\n",
      "            'use_gae': True,\n",
      "            'use_kl_loss': True,\n",
      "            'use_worker_filter_stats': True,\n",
      "            'validate_env_runners_after_construction': True,\n",
      "            'validate_offline_eval_runners_after_construction': True,\n",
      "            'vf_clip_param': 10.0,\n",
      "            'vf_loss_coeff': 1.0,\n",
      "            'vf_share_layers': -1,\n",
      "            'worker_cls': -1},\n",
      " 'date': '2025-06-08_01-39-43',\n",
      " 'done': False,\n",
      " 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0},\n",
      " 'env_runners': {'agent_episode_returns_mean': {'default_agent': -614.96},\n",
      "                 'env_reset_timer': np.float64(0.00033987000642810017),\n",
      "                 'env_step_timer': np.float64(7.55654651744309e-05),\n",
      "                 'env_to_module_connector': {'connector_pipeline_timer': np.float64(0.00017984483563791812),\n",
      "                                             'timers': {'connectors': {'add_observations_from_episodes_to_batch': np.float64(7.609652933423201e-06),\n",
      "                                                                       'add_states_from_episodes_to_batch': np.float64(4.311460536152594e-06),\n",
      "                                                                       'add_time_dim_to_batch_and_zero_pad': np.float64(7.221794176268306e-06),\n",
      "                                                                       'batch_individual_items': np.float64(2.07884004950055e-05),\n",
      "                                                                       'flatten_observations': np.float64(4.7363814350408186e-05),\n",
      "                                                                       'numpy_to_tensor': np.float64(3.582904641772994e-05)}}},\n",
      "                 'env_to_module_sum_episodes_length_in': np.float64(130.1392781249662),\n",
      "                 'env_to_module_sum_episodes_length_out': np.float64(130.1392781249662),\n",
      "                 'episode_duration_sec_mean': 0.19635981972212904,\n",
      "                 'episode_len_max': 200,\n",
      "                 'episode_len_mean': 195.92,\n",
      "                 'episode_len_min': 100,\n",
      "                 'episode_return_max': -322.0,\n",
      "                 'episode_return_mean': -614.96,\n",
      "                 'episode_return_min': -776.0,\n",
      "                 'module_episode_returns_mean': {'default_policy': -614.96},\n",
      "                 'module_to_env_connector': {'connector_pipeline_timer': np.float64(0.0003880928784519091),\n",
      "                                             'timers': {'connectors': {'get_actions': np.float64(0.00018668277339832823),\n",
      "                                                                       'listify_data_for_vector_env': np.float64(3.472181108725329e-05),\n",
      "                                                                       'normalize_and_clip_actions': np.float64(2.9522203190624577e-05),\n",
      "                                                                       'remove_single_ts_time_rank_from_batch': np.float64(1.954925043039813e-06),\n",
      "                                                                       'tensor_to_numpy': np.float64(5.284456866047384e-05),\n",
      "                                                                       'un_batch_to_individual_items': np.float64(1.7036672620289633e-05)}}},\n",
      "                 'num_agent_steps_sampled': {'default_agent': 4000},\n",
      "                 'num_agent_steps_sampled_lifetime': {'default_agent': 20000},\n",
      "                 'num_env_steps_sampled': 4000,\n",
      "                 'num_env_steps_sampled_lifetime': 20000,\n",
      "                 'num_env_steps_sampled_lifetime_throughput': 406.98623304702704,\n",
      "                 'num_episodes': 20,\n",
      "                 'num_episodes_lifetime': 102,\n",
      "                 'num_module_steps_sampled': {'default_policy': 4000},\n",
      "                 'num_module_steps_sampled_lifetime': {'default_policy': 20000},\n",
      "                 'rlmodule_inference_timer': np.float64(0.00014462433865811662),\n",
      "                 'sample': np.float64(1.8591043418768098),\n",
      "                 'time_between_sampling': np.float64(7.168437669640966),\n",
      "                 'weights_seq_no': 4.0},\n",
      " 'fault_tolerance': {'num_healthy_workers': 2, 'num_remote_worker_restarts': 0},\n",
      " 'hostname': 'brandon-ho-OMEN-by-HP-Laptop-15-dc0xxx',\n",
      " 'iterations_since_restore': 5,\n",
      " 'learners': {'__all_modules__': {'learner_connector': {'connector_pipeline_timer': 0.169663232739677,\n",
      "                                                        'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.06779637620842781,\n",
      "                                                                                  'add_observations_from_episodes_to_batch': 0.0002909277809278193,\n",
      "                                                                                  'add_one_ts_to_episodes_and_truncate': 0.008624914368958318,\n",
      "                                                                                  'add_states_from_episodes_to_batch': 7.5378878799303895e-06,\n",
      "                                                                                  'add_time_dim_to_batch_and_zero_pad': 2.28117878490246e-05,\n",
      "                                                                                  'batch_individual_items': 0.050053194443141415,\n",
      "                                                                                  'general_advantage_estimation': 0.04240434791160816,\n",
      "                                                                                  'numpy_to_tensor': 0.00015550634870894795}}},\n",
      "                                  'learner_connector_sum_episodes_length_in': 4000.0,\n",
      "                                  'learner_connector_sum_episodes_length_out': 4020.0015721796,\n",
      "                                  'num_env_steps_trained': 3792746,\n",
      "                                  'num_env_steps_trained_lifetime': 18960901,\n",
      "                                  'num_env_steps_trained_lifetime_throughput': 0.0,\n",
      "                                  'num_module_steps_trained': 120704,\n",
      "                                  'num_module_steps_trained_lifetime': 603520,\n",
      "                                  'num_non_trainable_parameters': 0.0,\n",
      "                                  'num_trainable_parameters': 389895.0},\n",
      "              'default_policy': {'curr_entropy_coeff': 0.0,\n",
      "                                 'curr_kl_coeff': 1.0125000476837158,\n",
      "                                 'default_optimizer_learning_rate': 5e-05,\n",
      "                                 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0),\n",
      "                                 'entropy': np.float32(1.6578755),\n",
      "                                 'gradients_default_optimizer_global_norm': np.float32(0.7563477),\n",
      "                                 'mean_kl_loss': np.float32(0.020609368),\n",
      "                                 'module_train_batch_size_mean': 128.0,\n",
      "                                 'num_module_steps_trained': 120704,\n",
      "                                 'num_module_steps_trained_lifetime': 603520,\n",
      "                                 'num_trainable_parameters': 389895.0,\n",
      "                                 'policy_loss': np.float32(-0.17687057),\n",
      "                                 'total_loss': np.float32(9.538874),\n",
      "                                 'vf_explained_var': np.float32(0.0028502345),\n",
      "                                 'vf_loss': np.float32(9.701834),\n",
      "                                 'vf_loss_unclipped': np.float32(30819.617),\n",
      "                                 'weights_seq_no': 5.0}},\n",
      " 'node_ip': '192.168.0.18',\n",
      " 'num_env_steps_sampled_lifetime': 20000,\n",
      " 'num_env_steps_sampled_lifetime_throughput': 406.98623304702704,\n",
      " 'num_training_step_calls_per_iteration': 1,\n",
      " 'perf': {'cpu_util_percent': np.float64(47.449999999999996),\n",
      "          'ram_util_percent': np.float64(33.578571428571436)},\n",
      " 'pid': 199634,\n",
      " 'time_since_restore': 47.399885177612305,\n",
      " 'time_this_iter_s': 9.801398038864136,\n",
      " 'time_total_s': 47.399885177612305,\n",
      " 'timers': {'env_runner_sampling_timer': 2.031248677620005,\n",
      "            'learner_update_timer': 6.9839777380840635,\n",
      "            'restore_env_runners': 1.960846010382142e-05,\n",
      "            'synch_env_connectors': 0.0018698721805443634,\n",
      "            'synch_weights': 0.00215759182466026,\n",
      "            'training_iteration': 9.019688503970965,\n",
      "            'training_step': 9.019452586264428},\n",
      " 'timestamp': 1749361183,\n",
      " 'training_iteration': 5,\n",
      " 'trial_id': 'default'}\n",
      "{'env_runners': {'agent_episode_returns_mean': {'default_agent': -553.9},\n",
      "                 'env_reset_timer': 0.0002918149984907359,\n",
      "                 'env_step_timer': 7.349070729441015e-05,\n",
      "                 'env_to_module_connector': {'connector_pipeline_timer': 0.00017370751096494426,\n",
      "                                             'timers': {'connectors': {'add_observations_from_episodes_to_batch': 7.414062209083268e-06,\n",
      "                                                                       'add_states_from_episodes_to_batch': 3.964962145169015e-06,\n",
      "                                                                       'add_time_dim_to_batch_and_zero_pad': 6.853675252592547e-06,\n",
      "                                                                       'batch_individual_items': 2.024786379987434e-05,\n",
      "                                                                       'flatten_observations': 4.630762044557267e-05,\n",
      "                                                                       'numpy_to_tensor': 3.442331951127949e-05}}},\n",
      "                 'env_to_module_sum_episodes_length_in': 129.85971308272983,\n",
      "                 'env_to_module_sum_episodes_length_out': 129.85971308272983,\n",
      "                 'episode_duration_sec_mean': 0.16030156040214932,\n",
      "                 'episode_len_max': 200,\n",
      "                 'episode_len_mean': 184.6,\n",
      "                 'episode_len_min': 66,\n",
      "                 'episode_return_max': -207.0,\n",
      "                 'episode_return_mean': -553.9,\n",
      "                 'episode_return_min': -704.0,\n",
      "                 'module_episode_returns_mean': {'default_policy': -553.9},\n",
      "                 'module_to_env_connector': {'connector_pipeline_timer': 0.00037558809802089305,\n",
      "                                             'timers': {'connectors': {'get_actions': 0.00017792236171340606,\n",
      "                                                                       'listify_data_for_vector_env': 3.433571703924991e-05,\n",
      "                                                                       'normalize_and_clip_actions': 2.8443846392146865e-05,\n",
      "                                                                       'remove_single_ts_time_rank_from_batch': 1.913162358857826e-06,\n",
      "                                                                       'tensor_to_numpy': 5.288047032316488e-05,\n",
      "                                                                       'un_batch_to_individual_items': 1.6086585038534214e-05}}},\n",
      "                 'num_agent_steps_sampled': {'default_agent': 1846},\n",
      "                 'num_agent_steps_sampled_lifetime': {'default_agent': 1846},\n",
      "                 'num_env_steps_sampled': 1846,\n",
      "                 'num_env_steps_sampled_lifetime': 1846,\n",
      "                 'num_episodes': 10,\n",
      "                 'num_episodes_lifetime': 10,\n",
      "                 'num_module_steps_sampled': {'default_policy': 1846},\n",
      "                 'num_module_steps_sampled_lifetime': {'default_policy': 1846},\n",
      "                 'rlmodule_inference_timer': 0.00013417485139039949,\n",
      "                 'sample': 1.6320158030139282,\n",
      "                 'weights_seq_no': 5.0}}\n"
     ]
    }
   ],
   "source": [
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from ray.rllib.connectors.env_to_module import FlattenObservations\n",
    "\n",
    "# Configure the algorithm.\n",
    "config = (\n",
    "    PPOConfig()\n",
    "    .environment(\"Taxi-v3\")\n",
    "    .env_runners(\n",
    "        num_env_runners=2,\n",
    "        # Observations are discrete (ints) -> We need to flatten (one-hot) them.\n",
    "        env_to_module_connector=lambda env: FlattenObservations(),\n",
    "    )\n",
    "    .evaluation(evaluation_num_env_runners=1)\n",
    ")\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# Build the algorithm.\n",
    "algo = config.build_algo()\n",
    "\n",
    "# Train it for 5 iterations ...\n",
    "for _ in range(5):\n",
    "    pprint(algo.train())\n",
    "\n",
    "# ... and evaluate it.\n",
    "pprint(algo.evaluate())\n",
    "\n",
    "# Release the algo's resources (remote actors, like EnvRunners and Learners).\n",
    "algo.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e867b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import random\n",
    "from copy import copy\n",
    "\n",
    "import numpy as np\n",
    "from gymnasium.spaces import Discrete, MultiDiscrete\n",
    "\n",
    "from pettingzoo import ParallelEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf1da701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([37, 42, 44])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultiDiscrete([7 * 7 - 1] * 3).sample()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mujoco_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
